{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ppcic_ml_ensemble_learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzV1vGXyJ6pK+1quUQQ2mr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLRG-CEFET-RJ/ml-class/blob/master/ppcic_ml_ensemble_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqO9URDlUCIZ",
        "colab_type": "text"
      },
      "source": [
        "# Aprendizado de Comitês (*Emsemble Learning*)\n",
        "\n",
        "Comitês são abordagens para combinar várias técnicas de aprendizado supervisionado para construir um único modelo preditivo. Comitês são aplicáveis às tarefas de classificação e de regressão.\n",
        "\n",
        "Durante o treinamento de um comitê, o objetivo é construir uma coleção de preditores que, juntos, produzem uma predição melhor do que cada um separadamente.\n",
        "\n",
        "\n",
        "Para ilustrar o funcionamento de modelos comitês, considere a figura abaixo ([fonte](https://)). Nessa figura, temos duas árvores de decisão induzidas. Considere que o problema de classificação (binária) a ser resolvido é predizer ser determinado indivíduo irá gostar (ou não) de um determinado jogo de vídeogames. Para cada um dos indíviduos testados, cada árvore produz um escore (pontuação) juntamente com a classe prevista. O que um modelo comitê faz é combinar os resultados de cada modelo componente para produzir a predição final.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/twocart.png)\n",
        "\n",
        "\n",
        "Normalmente, o modelo de comitê resultante tem qualidade preditiva melhor porque diminui a variância ou o viés quando comparado aos modelos componentes (do comitê).\n",
        "\n",
        "Conforme ilustra a figura a seguir ([fonte](https://ieeexplore.ieee.org/document/1688199)), a fronteira de decisão correspondente a um modelo de comitê pode ser aproximada por meio de uma combinação apropriada dos diferentes preditores (classificadores ou regressores) componentes.\n",
        "\n",
        "![alt text](https://www.researchgate.net/profile/Robi_Polikar/publication/3432431/figure/fig1/AS:670045000695819@1536762585849/Combining-classifiers-that-are-trained-on-different-subsets-of-the-training-data_W640.jpg)\n",
        "\n",
        "Um objetivo importante a ser alcançado durante o treinamento de modelo de comitê é atingir a diversidade, no sentido de que cada modelo componente possa complementar um eventual mal desempenho (em termos de qualidade preditiva) dos demais componentes em alguma região do espaço de atributos. Algumas abordagens para se obter diversidade são as seguintes:\n",
        "\n",
        "* Usar diferentes parâmetros de treinamento para a mesma família de classificadores;\n",
        "\n",
        "* Usar diferentes tipos de algoritmos de ML para treinar cada modelo componente;\n",
        "\n",
        "* Usar diferentes conjuntos de atributos para treinar cada modelo componente;\n",
        "\n",
        "* Manipular o conjunto de treinamento para treinar cada modelo componente com um conjunto de treinamento distinto dos usados nos demais componentes (essa é a abordagem mais comum).\n",
        "\n",
        "Há duas famílias de algoritmos para aprendizado de modelos de comitês, **Bagging** e **Boosting**, em cada uma das quais podemos encontrar vários algoritmos. A figura a seguir ilustra representantes e características principais de cada um dessas duas famílias.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1276/1*8T4HEjzHto_V8PrEFLkd9A.png)\n",
        "\n",
        "([fonte da figura](https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V7xGgtjdP_W",
        "colab_type": "text"
      },
      "source": [
        "### Bagging\n",
        "\n",
        "Bagging (termo proveniente de *bootstrap aggregation*) é uma abordagem baseada em comitê que produz $T$ modelos preditivos e combina os resultados desses $T$ modelos para realizar predição para um dado exemplo.\n",
        "\n",
        "Dado um conjunto de treinamento $X$ com $m$ exemplos, a técnica de bagging funciona de modo iterativo para construir o modelo comitê. Para iteração $t$ ($1 \\leq t \\leq T$), um conjunto de treinamento de treinamento $X_t$ de tamanho $m$ é gerado a partir de $X$, por meio de um processo conhecido como *amostragem com reposição* (*sampling with replacement*). Cada conjunto de treinamento $X_t$ é denominado uma *amostra de inicialização* (*bootstrap sample*). Dessa forma, a diversidade é obtida no bagging com o uso de diferentes subconjuntos de dados aleatoriamente criados com reposição a partir do único conjunto de dados original.\n",
        "\n",
        "Repare que, porque a amostragem com reposição é utilizada para produzir cada $X_t$, alguns exemplos em cada conjunto de treinamento gerado podem ocorrer mais de uma vez, enquanto que outras intâncias podem não ser selecionadas para compor $X_t$. \n",
        "\n",
        "Para cada $X_t$, um modelo de predição é ajustado. Cada conjunto $X_t$ (*bootstrap sample*) é usado para treinar um modelo preditor $M_t$. Além disso, todos os modelos preditores gerados são do mesmo tipo (i.e., usam a mesma representação). \n",
        "\n",
        "No contexto da tarefa de classificação, para predizer a classe de uma instância $\\mathbf{x}$, cada modelo $M_t$ é usado para produzir uma resposta. O modelo comitê (composto de todos os $M_t$ classificadores) produz como resposta a classe majoritariamente produzida pelos seus componentes. \n",
        "  \n",
        "O bagging também pode ser aplicado à tarefa de regressão (i.e., para realizar previsão de valores contínuos). Nesse caso, em vez da classe majoritária, o modelo comitê computa o valor médio das previsões produzidas pelos $T$ modelos base.\n",
        "\n",
        "Vantagens do Bagging:\n",
        "* Possibilidade de treinamento em paralelo: cada modelo componente pode ser construído de forma independente.\n",
        "\n",
        "* Adequado quando o algoritmo de ML utilizado gera modelos componentes de baixo viés e de alta variância (i.e., modelos complexos)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvnBUYfd6UeT",
        "colab_type": "text"
      },
      "source": [
        "#### Passos\n",
        "\n",
        "Os passos a seguir resumem a técnica de geração de um modelo de comitê por meio da técnica *bagging*:\n",
        "\n",
        "* Seja $m = |X|$ (quantidade de exemplos de treinamento)\n",
        "\n",
        "* Para cada iteração $t$:\n",
        "\n",
        "  * Gerar uma bootstrap sample $X_t$ de tamanho $m$.\n",
        "  \n",
        "  * Aplicar o algoritmo de aprendizado sobre $X_t$ para gerar o modelo de predição $M_t$\n",
        "\n",
        "  * Armazenar o modelo resultante\n",
        "\n",
        "Predição (classificação) para $\\mathbf{x}$:\n",
        "\n",
        "* Para cada um dos $T$ modelos:\n",
        "\n",
        "  * Predizer a classe do exemplo $\\mathbf{x}$ usando $M_t$\n",
        "\n",
        "  * Retornar a classe que foi prevista mais vezes (*voting*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2xcxKQX6LAx",
        "colab_type": "text"
      },
      "source": [
        "#### Classe BaggingClassifier\n",
        "\n",
        "No Scikit-Learn, a classe [BaggingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) pode ser usada para gerar modelos comitês para classificação por meio da técnica *bagging*. Um dos parâmetros de iniciação dessa classe é `base_estimator`, que indica qual o algoritmo a ser utilizado para gerar cada componente do comitê. A célula de código a seguir ([fonte](https://www.kaggle.com/dillonkoch18/bagging-classifier-titanic-submission) ) ilustra um exemplo de uso dessa classe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unV-DaRO-hyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "e6e32286-87e5-4923-b748-0de7be5be60f"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "rng = 42\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data,\n",
        "                                                    iris.target,\n",
        "                                                    random_state=rng)\n",
        "\n",
        "# cria o classificador\n",
        "params = {'n_estimators': [40, 42], 'base_estimator__max_leaf_nodes':[10, 15], 'base_estimator__max_depth':[4, 5, 6]}\n",
        "dt = DecisionTreeClassifier()\n",
        "bc = BaggingClassifier(base_estimator=dt, oob_score=True, random_state=1)\n",
        "\n",
        "# aplica busca em grade para determinar os melhores parâmetros\n",
        "bc_grid = GridSearchCV(estimator=bc, param_grid=params, scoring='accuracy', cv=5, n_jobs=-1)\n",
        "bc_grid.fit(X_train, y_train)\n",
        "best_params = bc_grid.best_params_\n",
        "print(best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'base_estimator__max_depth': 4, 'base_estimator__max_leaf_nodes': 10, 'n_estimators': 40}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAfsSMUD3YOC",
        "colab_type": "text"
      },
      "source": [
        "#### Florestas Aleatórias (*Random Forests*)\n",
        "\n",
        "Random Forests é um caso particular de bagging. Aqui também selecionamos amostras de bootstrap do conjunto de treinamento. No entanto, também são amostrados subconjuntos aleatórios de atributos (*features*) para treinar as árvores individuais. No bagging genérico, um conjunto de dados com todos os atributos contidos em $X$ seria usado para ajustar cada árvore de decisão.\n",
        "\n",
        "Devido à seleção aleatória de atributos, as árvores são mais independentes (i.e., diferentes) umas das outras do que no bagging, o que contribui para aumentar a diversidade dos modelos componentes.\n",
        "\n",
        "Efeitos (quando comparamos ao bagging): \n",
        "\n",
        "* melhor desempenho preditivo; \n",
        "* mais rápido, porque cada árvore aprende a partir de um subconjunto próprio do conjunto de todos os atributos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjbag-KnFgUa",
        "colab_type": "text"
      },
      "source": [
        "#### Classe RandomForestClassifier\n",
        "\n",
        "No Scikit-Learn, a classe [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) implementa o algoritmo de Florestas Aleatórias. Um dos parâmetros de inicialização dessa classe é `n_estimators`, que indica a quantidade de árvores que devem compor o modelo comitê resultante. O exemplo a seguir ilustra o uso dessa classe sobre o conjunto de dados Iris."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbPqhVmbEs-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "23ec56dc-e322-4b23-bf19-fdee7f90a282"
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "print(iris.target_names)\n",
        "\n",
        "print(iris.feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QwpZXNmExV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "88a82585-53a0-4850-8fe6-2c266bb0dfe8"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.DataFrame({\n",
        "    'sepal length':iris.data[:,0],\n",
        "    'sepal width':iris.data[:,1],\n",
        "    'petal length':iris.data[:,2],\n",
        "    'petal width':iris.data[:,3],\n",
        "    'species':iris.target\n",
        "})\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length</th>\n",
              "      <th>sepal width</th>\n",
              "      <th>petal length</th>\n",
              "      <th>petal width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length  sepal width  petal length  petal width  species\n",
              "0           5.1          3.5           1.4          0.2        0\n",
              "1           4.9          3.0           1.4          0.2        0\n",
              "2           4.7          3.2           1.3          0.2        0\n",
              "3           4.6          3.1           1.5          0.2        0\n",
              "4           5.0          3.6           1.4          0.2        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS879QJ7E4tR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data[['sepal length', 'sepal width', 'petal length', 'petal width']]\n",
        "y = data['species']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiAh4RnYE8jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-65ZfWKFCZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a812eda-10ec-405e-9d0c-5a45e6c7eb48"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"Acurácia:\", metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia: 0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wFze1ELKEP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5dca0bd3-399a-4bd4-a26d-24a7eed0eaa3"
      },
      "source": [
        "clf.predict([[3, 5, 4, 2]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HooVcPZIKE2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "040eb596-c923-497a-ace1-d90c4876c717"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "clf.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQC-de6TIV5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXKqN0nZIdoy",
        "colab_type": "text"
      },
      "source": [
        "Um dos atributos da classe `RandomForestClassifier` é `feature_importances_`, que permite inspecionar qual a contribuição de cada atributo para a força preditiva do modelo gerado (quanto mais importante o atributo, mais alto é o valor correspondente). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfOhRl2UKTeZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "11fcada9-7e1f-4f43-b55e-fd6ef6f992e6"
      },
      "source": [
        "import pandas as pd\n",
        "feature_imp = pd.Series(clf.feature_importances_, index = iris.feature_names).sort_values(ascending = False)\n",
        "feature_imp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "petal width (cm)     0.438652\n",
              "petal length (cm)    0.438511\n",
              "sepal length (cm)    0.092768\n",
              "sepal width (cm)     0.030069\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5EN5TfsJXan",
        "colab_type": "text"
      },
      "source": [
        "O código a seguir gera uma representação gráfica das importâncias de cada atributo do conjunto Iris sobre o modelo comitê gerado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsEmUMI1Kahk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "ccdc8ff2-efe3-4121-fbe3-a79c398737a3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
        "\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAEWCAYAAAAEvMzxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7foIbl9m2A4",
        "colab_type": "text"
      },
      "source": [
        "## Boosting\n",
        "\n",
        "Na técnica de *boosting*, o treinamento do modelo comitê é realizado de forma **sequencial**: em cada passo, o algoritmo tenta adicionar um novo modelo componente que é melhor em regiões (do espaço de atributos) nas quais os modelos anteriormente adicionados ao comitê erraram. Para isso, exemplos que foram incorretamente classificados pelos componentes já ajustados possuem maior probabilidade de serem selecionados para ajustar novos componentes, conforme ilustra a figura a seguir ([fonte](https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/)).\n",
        "![alt text](https://quantdare.com/wp-content/uploads/2016/04/bb2-800x307.png)\n",
        "Algoritmos de *boosting* são adequados para compor modelos gerados por algoritmos que produzem modelos de viés alto e de baixa variância.\n",
        "\n",
        "A figura a seguir ([fonte](https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/)) ilustra de forma esquemática a diferença entre as abordagens *bagging* e *boosting*.\n",
        "![alt text](https://quantdare.com/wp-content/uploads/2016/04/bb3-800x307.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE8Yi9DQ5tye",
        "colab_type": "text"
      },
      "source": [
        "### Aprendizes: fracos e fortes\n",
        "\n",
        "Um **aprendiz fraco** (*weak learner*) é definido como um classificador que é apenas ligeiramente correlacionado com a classificação verdadeira. Ou seja, um aprendiz fraco pode rotular exemplos com acurácia igual a $1/2 + \\alpha$, onde $\\alpha$ é um valor pequeno e positivo. Isso significa que em um weak learner, o desempenho em qualquer conjunto de treinamento é ligeiramente melhor que a previsão ao acaso.\n",
        "\n",
        "Em contraste, um **aprendiz forte** (*strong learner*) é um classificador que é arbitrariamente bem correlacionado com a classificação verdadeira.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsaemkaFn0B8",
        "colab_type": "text"
      },
      "source": [
        "### AdaBoost\n",
        "\n",
        "O AdaBoost é uma das primeiros métodos de boosting. Este método mantém uma lista de pesos, um para cada um dos $m$ exemplos do conjunto de treinamento.\n",
        "\n",
        "1. Iniciar pesos com valores uniformes ($1/m$)\n",
        "2. Iterar:\n",
        "  * Aplicar aprendiz $L$ aos exemplos ponderados\n",
        "  * Aumentar pesos dos exemplos classificados incorretamente por $L$.\n",
        "3. Combinar modelos por votação ponderada\n",
        "\n",
        "Em cada iteração (passo 2 acima), os pesos dos exemplos são alterados de tal forma a fazer com que o próximo aprendiz priorize os exemplos que o aprendiz anterior classificou incorretamente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXq83-pMVzs5",
        "colab_type": "text"
      },
      "source": [
        "### Class AdaBoostClassifier\n",
        "\n",
        "No Scikit-Learn, a classe [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) implementa o algoritmo AdaBoost. As células a seguir ilustram o uso dessa classe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLxVe15KrajC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JgRgJRuura46",
        "colab": {}
      },
      "source": [
        "# Realiza a carga do dados\n",
        "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jNa2hn22ra5A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b5b62ac-5192-43a5-fe6a-fcd72d59a800"
      },
      "source": [
        "# Define as matrizes de dados e alvo\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(768, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gdD__iRara5E",
        "colab": {}
      },
      "source": [
        "# Divide os dados para treinamento e teste\n",
        "seed = 7\n",
        "test_size = 0.33\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwwt6AxcoSJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "378394ab-14e8-4869-c947-eff268bcf62a"
      },
      "source": [
        "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "clf.fit(X, y)  \n",
        "\n",
        "print(clf.feature_importances_ )\n",
        "\n",
        "y_pred = clf.predict(X)\n",
        "\n",
        "print(confusion_matrix(y, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.06 0.23 0.06 0.04 0.11 0.16 0.26 0.08]\n",
            "[[445  55]\n",
            " [ 69 199]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xKGXwPu53Sa",
        "colab_type": "text"
      },
      "source": [
        "### Gradient boosting\n",
        "\n",
        "A abordagem mais popular de boosting é o Gradient Boosting. Outros nomes para este mesmo método: *multiple additive regression trees*, *stochastic gradient boosting*, *gradient boosting machines*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqJ0h9lYSUor",
        "colab_type": "text"
      },
      "source": [
        "### XGBoost\n",
        "\n",
        "O [XGBoost](https://xgboost.ai/) (*Extreme Gradient Boosting*) é a implementação de gradient boosting mais utilizada atualmente. Essa implementação foi desenvolvida por [Tianqi Chen](https://tqchen.com).\n",
        "\n",
        "O modelo que o XGBoost produz é um comitê em que cada componente é uma árvore de decisão. Sendo assim, a representação usada no modelo resultante no XGBoost é a mesma usada no método *Random Forests*. A diferença está na forma pela qual o comitê de árvores é construído durante o aprendizado. O XGBoost define uma função objetivo a ser otimizada durante o aprendizado, por meio do método de otimização [Newton-Raphson](https://en.wikipedia.org/wiki/Newton%27s_method), que é similar ao método [Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent). \n",
        "\n",
        "Suponha que $f_t$ ($1 \\leq t \\leq T$) representa uma das $T$ árvores componentes de um modelo comitê produzido pelo XGBoost. Cada árvore é um elemento do conjunto $\\mathcal{F}$, o espaço de árvores compatíveis com o conjunto de treinamento utilizado, $f_t \\in \\mathcal{F}$. O escore produzido pelo comitê de árvores para o exemplo $x^{(i)}$ é dado pela fórmula a seguir:\n",
        "\n",
        "$$\n",
        "\\hat{y}^{(i)} = \\sum_{k=1}^T f_t(x^{(i)})\n",
        "$$\n",
        "\n",
        "Durante o aprendizado, o XGBoost procura minimizar a seguinte função objetivo:\n",
        "\n",
        "$$\n",
        "\\text{obj} = \\sum_{t=1}^m l(y^{(i)}, \\hat{y}^{(i)}) + \\sum_{i=1}^T\\Omega(f_t)\n",
        "$$\n",
        "\n",
        "Otimizar todas as árvores do comitê de uma única vez é intratável computacionalmente. Por conta disso é que o XGBoost usa um procecimento de otmização aditivo, no qual ocorre a otimização de uma árvore por vez.\n",
        "$$\n",
        "\\begin{split}\n",
        "\\hat{y}_0^{(i)} &= 0\\\\\n",
        "\\hat{y}_1^{(i)} &= f_1(x^{(i)}) = \\hat{y}_0^{(i)} + f_1(x^{(i)})\\\\\n",
        "\\hat{y}_2^{(i)} &= f_1(x^{(i)}) + f_2(x^{(i)})= \\hat{y}_1^{(i)} + f_2(x^{(i)})\\\\\n",
        "&\\dots\\\\\n",
        "\\hat{y}_t^{(i)} &= \\sum_{k=1}^t f_k(x^{(i)})= \\hat{y}_{t-1}^{(i)} + f_t(x^{(i)})\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "É possível provar (veja detalhes no artigo fonte) que a função objetivo a ser otimizada para selecionar a $t$-ésima árvore é a seguinte:\n",
        "\n",
        "$$\n",
        "\\operatorname{obj}_t = \\sum_{i=1}^m [g_i f_t(x^{(i)}) + \\frac{1}{2} h_i f_t^2(x^{(i)})] + \\Omega(f_t)\n",
        "$$\n",
        "\n",
        "Na expressão acima, $g_i$ e $h_i$ são as derivadas parciais de primeira e de segunda ordem da função $l$ com relação a $\\hat{y}_{i-1}^{(i)}$.\n",
        "\n",
        "$$\n",
        "\\begin{split}\n",
        "g_i &= \\partial_{\\hat{y}^{(t)}_{t-1}} l(y^{(i)}, \\hat{y}^{(i)}_{t-1})\\\\\n",
        "h_i &= \\partial_{\\hat{y}^{(i)}_{t-1}}^2 l(y^{(i)}, \\hat{y}^{(i)}_{t-1})\n",
        "\\end{split}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9L-Wr_EhW89",
        "colab_type": "text"
      },
      "source": [
        "Há duas classes classes empacotadoras para utilizar a implementação fornecida pelo [XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn) com o Scikit-Learn: `XGBClassifier` e `XGBRegressor`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJIclsgT--8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJqmHbdF_FL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Realiza a carga do dados\n",
        "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11PvQ7zH_Kwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define as matrizes de dados e alvo\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttu2ptaU_OyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Divide os dados para treinamento e teste\n",
        "seed = 7\n",
        "test_size = 0.33\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q33r19ydSYij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "bc721d77-b5bf-424d-8eed-e350457b327b"
      },
      "source": [
        "# Ajusta o modelo\n",
        "model = XGBClassifier()\n",
        "print(model)\n",
        "model.fit(X_train, \n",
        "          y_train, \n",
        "          eval_metric = \"logloss\", \n",
        "          verbose = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I6JXnE__hql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c13bbee6-cef1-458c-fdee-4dbb00fd9a8e"
      },
      "source": [
        "# make predictions for test data\n",
        "y_pred = model.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "\n",
        "# Avalia a acurária do modelo preditivo\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 77.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyad2bddkIB6",
        "colab_type": "text"
      },
      "source": [
        "#### Outros exemplos\n",
        "\n",
        "Os exemplos a seguir ([fonte](https://www.kaggle.com/stuarthallows/using-xgboost-with-scikit-learn)) ilustram diferentes usos das classes `XGBClassifier` e `XGBRegressor`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLtOOUP5iACK",
        "colab_type": "text"
      },
      "source": [
        "##### Regressão\n",
        "\n",
        "O exemplo a seguir ilustra o uso do XGBoost para a tarefa de regressão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZIXnTPViG6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
        "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
        "\n",
        "import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZYVo0emiNJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bcc9ceb7-a4ca-46bd-a766-56b6da37f372"
      },
      "source": [
        "diabetes = load_diabetes()\n",
        "\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
        "\n",
        "xgb_model.fit(X, y)\n",
        "\n",
        "y_pred = xgb_model.predict(X)\n",
        "\n",
        "mse=mean_squared_error(y, y_pred)\n",
        "\n",
        "print(np.sqrt(mse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36.271203581682585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br3LxxJHiUh8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "c6aa53f2-9c84-4b7d-81fe-a4d2c7e423d9"
      },
      "source": [
        "xgb_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
              "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
              "             random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "             seed=None, silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Wh-vd_kiddx",
        "colab_type": "text"
      },
      "source": [
        "##### Classificação binária"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOis7Tx8iYCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "48e3c689-a265-4bf2-b82b-0ade09508e40"
      },
      "source": [
        "cancer = load_breast_cancer()\n",
        "\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
        "xgb_model.fit(X, y)\n",
        "\n",
        "y_pred = xgb_model.predict(X)\n",
        "\n",
        "print(confusion_matrix(y, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[212   0]\n",
            " [  0 357]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-UhMuYViy55",
        "colab_type": "text"
      },
      "source": [
        "##### Classificação multiclasses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEX8_y3Ui1iY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9727fb86-9398-4292-ec44-696d66dbe800"
      },
      "source": [
        "wine = load_wine()\n",
        "\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
        "xgb_model.fit(X, y)\n",
        "\n",
        "y_pred = xgb_model.predict(X)\n",
        "\n",
        "print(confusion_matrix(y, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[59  0  0]\n",
            " [ 0 71  0]\n",
            " [ 0  0 48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "var2KbrAjsN2",
        "colab_type": "text"
      },
      "source": [
        "##### Validação cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LeCqWA4juxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b1c04e9c-0d9b-477f-8809-d85ce3830bc3"
      },
      "source": [
        "def display_scores(scores):\n",
        "    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))\n",
        "\n",
        "diabetes = load_diabetes()\n",
        "\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scores = []\n",
        "\n",
        "for train_index, test_index in kfold.split(X):   \n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\")\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred = xgb_model.predict(X_test)\n",
        "    \n",
        "    scores.append(mean_squared_error(y_test, y_pred))\n",
        "    \n",
        "display_scores(np.sqrt(scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [55.30444573 55.59151472 63.44642064 57.82986083 58.71808276]\n",
            "Mean: 58.178\n",
            "Std: 2.937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgNyVVEm4_4m",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Bagging x Boosting\n",
        "* Bagging  e Random Forests são algoritmos que visam reduzir a complexidade de modelos que se sobreajustam aos dados de treinamento. \n",
        "** Bagging pode degradar o desempenho de algoritmos estáveis (por exemplo, k-NN), porque conjuntos de treinamento efetivamente menores são usados para treinar cada classificador.\n",
        "* Em contraste, boosting é uma abordagem para aumentar a complexidade de modelos que sofrem de alto viés, i.e., que se subajustam aos dados de treinamento.\n"
      ]
    }
  ]
}