{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ppcic_ml_ann_keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMbPGbaGXEyfgf/WunzCjAW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLRG-CEFET-RJ/ml-class/blob/master/ppcic_ml_ann_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac4Fr6oNcwtf"
      },
      "source": [
        "# Example 1: ANN to learn to XOR function\n",
        "\n",
        "This example trains a very simple neural network to solve the XOR problem.\n",
        "\n",
        "![link text](https://www.tech-quantum.com/wp-content/uploads/2019/03/XOR-Problem-768x433.png)\n",
        "\n",
        "Notice that this a binary classification problem. The training set has four examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgOGjx5Xb7HI"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "\n",
        "model = Sequential()\n",
        "l1 = Dense(16, input_dim=2, activation='relu')\n",
        "model.add(l1)\n",
        "l2 = Dense(1, activation='sigmoid')\n",
        "model.add(l2)\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfuTeErBfnqV",
        "outputId": "cfecf678-fe74-49fc-a94d-b3d143941d1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_25 (Dense)             (None, 16)                48        \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 65\n",
            "Trainable params: 65\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di5RgRw9_jdj"
      },
      "source": [
        "The image below (generated with this [tool](http://alexlenail.me/NN-SVG/index.html)) provides a visual perspective of the architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRh5ZJIcjLAs",
        "outputId": "8a4ea8fa-d67d-463a-aa3b-f86cc253aeeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        }
      },
      "source": [
        "%%html\n",
        "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1400\" height=\"800\" style=\"cursor: move;\"><g transform=\"translate(31.029124448207995,22.95774483714024) scale(0.9619274546647754)\"><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,90\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,130\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,170\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,210\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,250\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,290\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,330\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,370\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,410\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,450\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,490\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,530\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,90\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,130\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,170\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,210\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,250\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,290\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,330\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,370\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,410\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,450\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,490\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,530\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,90, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,130, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,170, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,210, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,250, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,290, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,330, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,370, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,410, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,450, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,490, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,530, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,570\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,610\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,650\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,690\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,570\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,610\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,650\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,690\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,570, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,610, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,650, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,690, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><circle r=\"10\" class=\"node\" id=\"0_0\" cx=\"540\" cy=\"370\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"0_1\" cx=\"540\" cy=\"410\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_0\" cx=\"720\" cy=\"90\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_1\" cx=\"720\" cy=\"130\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_2\" cx=\"720\" cy=\"170\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_3\" cx=\"720\" cy=\"210\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_4\" cx=\"720\" cy=\"250\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_5\" cx=\"720\" cy=\"290\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_6\" cx=\"720\" cy=\"330\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_7\" cx=\"720\" cy=\"370\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_8\" cx=\"720\" cy=\"410\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_9\" cx=\"720\" cy=\"450\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_10\" cx=\"720\" cy=\"490\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_11\" cx=\"720\" cy=\"530\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_12\" cx=\"720\" cy=\"570\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_13\" cx=\"720\" cy=\"610\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_14\" cx=\"720\" cy=\"650\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_15\" cx=\"720\" cy=\"690\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"2_0\" cx=\"900\" cy=\"390\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><text class=\"text\" dy=\".35em\" x=\"505\" y=\"730\" style=\"font-size: 12px;\">Input Layer ∈ ℝ²</text><text class=\"text\" dy=\".35em\" x=\"685\" y=\"730\" style=\"font-size: 12px;\">Hidden Layer ∈ ℝ¹⁶</text><text class=\"text\" dy=\".35em\" x=\"865\" y=\"730\" style=\"font-size: 12px;\">Output Layer ∈ ℝ¹</text></g><defs><marker id=\"arrow\" viewBox=\"0 -5 10 10\" markerWidth=\"7\" markerHeight=\"7\" orient=\"auto\" refX=\"40\"><path d=\"M0,-5L10,0L0,5\" style=\"stroke: rgb(80, 80, 80); fill: none;\"></path></marker></defs></svg>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1400\" height=\"800\" style=\"cursor: move;\"><g transform=\"translate(31.029124448207995,22.95774483714024) scale(0.9619274546647754)\"><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,90\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,130\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,170\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,210\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,250\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,290\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,330\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,370\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,410\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,450\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,490\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,530\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,90\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,130\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,170\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,210\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,250\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,290\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,330\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,370\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,410\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,450\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,490\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,530\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,90, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,130, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,170, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,210, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,250, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,290, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,330, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,370, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,410, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,450, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,490, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,530, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,570\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,610\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,650\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,690\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,570\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,610\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,650\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,690\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,570, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,610, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,650, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,690, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><circle r=\"10\" class=\"node\" id=\"0_0\" cx=\"540\" cy=\"370\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"0_1\" cx=\"540\" cy=\"410\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_0\" cx=\"720\" cy=\"90\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_1\" cx=\"720\" cy=\"130\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_2\" cx=\"720\" cy=\"170\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_3\" cx=\"720\" cy=\"210\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_4\" cx=\"720\" cy=\"250\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_5\" cx=\"720\" cy=\"290\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_6\" cx=\"720\" cy=\"330\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_7\" cx=\"720\" cy=\"370\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_8\" cx=\"720\" cy=\"410\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_9\" cx=\"720\" cy=\"450\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_10\" cx=\"720\" cy=\"490\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_11\" cx=\"720\" cy=\"530\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_12\" cx=\"720\" cy=\"570\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_13\" cx=\"720\" cy=\"610\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_14\" cx=\"720\" cy=\"650\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_15\" cx=\"720\" cy=\"690\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"2_0\" cx=\"900\" cy=\"390\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><text class=\"text\" dy=\".35em\" x=\"505\" y=\"730\" style=\"font-size: 12px;\">Input Layer ∈ ℝ²</text><text class=\"text\" dy=\".35em\" x=\"685\" y=\"730\" style=\"font-size: 12px;\">Hidden Layer ∈ ℝ¹⁶</text><text class=\"text\" dy=\".35em\" x=\"865\" y=\"730\" style=\"font-size: 12px;\">Output Layer ∈ ℝ¹</text></g><defs><marker id=\"arrow\" viewBox=\"0 -5 10 10\" markerWidth=\"7\" markerHeight=\"7\" orient=\"auto\" refX=\"40\"><path d=\"M0,-5L10,0L0,5\" style=\"stroke: rgb(80, 80, 80); fill: none;\"></path></marker></defs></svg>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzIIgYx3fpqA",
        "outputId": "da0e6848-58be-4bf0-d89f-17413be0495d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X = np.array([[0,0],[0,1],[1,0],[1,1]], \"float32\")\n",
        "y = np.array([[0],[1],[1],[0]], \"float32\")\n",
        "\n",
        "model.fit(X, y, epochs=500, verbose=2)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1/1 - 0s - loss: 0.2599 - binary_accuracy: 0.5000\n",
            "Epoch 2/500\n",
            "1/1 - 0s - loss: 0.2594 - binary_accuracy: 0.2500\n",
            "Epoch 3/500\n",
            "1/1 - 0s - loss: 0.2589 - binary_accuracy: 0.2500\n",
            "Epoch 4/500\n",
            "1/1 - 0s - loss: 0.2583 - binary_accuracy: 0.2500\n",
            "Epoch 5/500\n",
            "1/1 - 0s - loss: 0.2579 - binary_accuracy: 0.2500\n",
            "Epoch 6/500\n",
            "1/1 - 0s - loss: 0.2574 - binary_accuracy: 0.2500\n",
            "Epoch 7/500\n",
            "1/1 - 0s - loss: 0.2569 - binary_accuracy: 0.2500\n",
            "Epoch 8/500\n",
            "1/1 - 0s - loss: 0.2564 - binary_accuracy: 0.2500\n",
            "Epoch 9/500\n",
            "1/1 - 0s - loss: 0.2560 - binary_accuracy: 0.2500\n",
            "Epoch 10/500\n",
            "1/1 - 0s - loss: 0.2555 - binary_accuracy: 0.2500\n",
            "Epoch 11/500\n",
            "1/1 - 0s - loss: 0.2551 - binary_accuracy: 0.2500\n",
            "Epoch 12/500\n",
            "1/1 - 0s - loss: 0.2547 - binary_accuracy: 0.2500\n",
            "Epoch 13/500\n",
            "1/1 - 0s - loss: 0.2542 - binary_accuracy: 0.2500\n",
            "Epoch 14/500\n",
            "1/1 - 0s - loss: 0.2538 - binary_accuracy: 0.2500\n",
            "Epoch 15/500\n",
            "1/1 - 0s - loss: 0.2534 - binary_accuracy: 0.5000\n",
            "Epoch 16/500\n",
            "1/1 - 0s - loss: 0.2530 - binary_accuracy: 0.5000\n",
            "Epoch 17/500\n",
            "1/1 - 0s - loss: 0.2526 - binary_accuracy: 0.5000\n",
            "Epoch 18/500\n",
            "1/1 - 0s - loss: 0.2523 - binary_accuracy: 0.5000\n",
            "Epoch 19/500\n",
            "1/1 - 0s - loss: 0.2519 - binary_accuracy: 0.5000\n",
            "Epoch 20/500\n",
            "1/1 - 0s - loss: 0.2515 - binary_accuracy: 0.5000\n",
            "Epoch 21/500\n",
            "1/1 - 0s - loss: 0.2512 - binary_accuracy: 0.5000\n",
            "Epoch 22/500\n",
            "1/1 - 0s - loss: 0.2508 - binary_accuracy: 0.5000\n",
            "Epoch 23/500\n",
            "1/1 - 0s - loss: 0.2505 - binary_accuracy: 0.5000\n",
            "Epoch 24/500\n",
            "1/1 - 0s - loss: 0.2501 - binary_accuracy: 0.5000\n",
            "Epoch 25/500\n",
            "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000\n",
            "Epoch 26/500\n",
            "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000\n",
            "Epoch 27/500\n",
            "1/1 - 0s - loss: 0.2492 - binary_accuracy: 0.5000\n",
            "Epoch 28/500\n",
            "1/1 - 0s - loss: 0.2488 - binary_accuracy: 0.5000\n",
            "Epoch 29/500\n",
            "1/1 - 0s - loss: 0.2485 - binary_accuracy: 0.5000\n",
            "Epoch 30/500\n",
            "1/1 - 0s - loss: 0.2482 - binary_accuracy: 0.5000\n",
            "Epoch 31/500\n",
            "1/1 - 0s - loss: 0.2479 - binary_accuracy: 0.5000\n",
            "Epoch 32/500\n",
            "1/1 - 0s - loss: 0.2476 - binary_accuracy: 0.5000\n",
            "Epoch 33/500\n",
            "1/1 - 0s - loss: 0.2473 - binary_accuracy: 0.5000\n",
            "Epoch 34/500\n",
            "1/1 - 0s - loss: 0.2471 - binary_accuracy: 0.5000\n",
            "Epoch 35/500\n",
            "1/1 - 0s - loss: 0.2468 - binary_accuracy: 0.5000\n",
            "Epoch 36/500\n",
            "1/1 - 0s - loss: 0.2465 - binary_accuracy: 0.5000\n",
            "Epoch 37/500\n",
            "1/1 - 0s - loss: 0.2462 - binary_accuracy: 0.5000\n",
            "Epoch 38/500\n",
            "1/1 - 0s - loss: 0.2459 - binary_accuracy: 0.5000\n",
            "Epoch 39/500\n",
            "1/1 - 0s - loss: 0.2456 - binary_accuracy: 0.5000\n",
            "Epoch 40/500\n",
            "1/1 - 0s - loss: 0.2453 - binary_accuracy: 0.5000\n",
            "Epoch 41/500\n",
            "1/1 - 0s - loss: 0.2451 - binary_accuracy: 0.5000\n",
            "Epoch 42/500\n",
            "1/1 - 0s - loss: 0.2448 - binary_accuracy: 0.5000\n",
            "Epoch 43/500\n",
            "1/1 - 0s - loss: 0.2445 - binary_accuracy: 0.5000\n",
            "Epoch 44/500\n",
            "1/1 - 0s - loss: 0.2442 - binary_accuracy: 0.5000\n",
            "Epoch 45/500\n",
            "1/1 - 0s - loss: 0.2439 - binary_accuracy: 0.5000\n",
            "Epoch 46/500\n",
            "1/1 - 0s - loss: 0.2437 - binary_accuracy: 0.5000\n",
            "Epoch 47/500\n",
            "1/1 - 0s - loss: 0.2434 - binary_accuracy: 0.5000\n",
            "Epoch 48/500\n",
            "1/1 - 0s - loss: 0.2431 - binary_accuracy: 0.5000\n",
            "Epoch 49/500\n",
            "1/1 - 0s - loss: 0.2428 - binary_accuracy: 0.5000\n",
            "Epoch 50/500\n",
            "1/1 - 0s - loss: 0.2426 - binary_accuracy: 0.5000\n",
            "Epoch 51/500\n",
            "1/1 - 0s - loss: 0.2423 - binary_accuracy: 0.5000\n",
            "Epoch 52/500\n",
            "1/1 - 0s - loss: 0.2420 - binary_accuracy: 0.5000\n",
            "Epoch 53/500\n",
            "1/1 - 0s - loss: 0.2417 - binary_accuracy: 0.5000\n",
            "Epoch 54/500\n",
            "1/1 - 0s - loss: 0.2414 - binary_accuracy: 0.5000\n",
            "Epoch 55/500\n",
            "1/1 - 0s - loss: 0.2411 - binary_accuracy: 0.5000\n",
            "Epoch 56/500\n",
            "1/1 - 0s - loss: 0.2409 - binary_accuracy: 0.5000\n",
            "Epoch 57/500\n",
            "1/1 - 0s - loss: 0.2406 - binary_accuracy: 0.5000\n",
            "Epoch 58/500\n",
            "1/1 - 0s - loss: 0.2403 - binary_accuracy: 0.5000\n",
            "Epoch 59/500\n",
            "1/1 - 0s - loss: 0.2400 - binary_accuracy: 0.5000\n",
            "Epoch 60/500\n",
            "1/1 - 0s - loss: 0.2397 - binary_accuracy: 0.5000\n",
            "Epoch 61/500\n",
            "1/1 - 0s - loss: 0.2394 - binary_accuracy: 0.5000\n",
            "Epoch 62/500\n",
            "1/1 - 0s - loss: 0.2391 - binary_accuracy: 0.5000\n",
            "Epoch 63/500\n",
            "1/1 - 0s - loss: 0.2389 - binary_accuracy: 0.5000\n",
            "Epoch 64/500\n",
            "1/1 - 0s - loss: 0.2386 - binary_accuracy: 0.5000\n",
            "Epoch 65/500\n",
            "1/1 - 0s - loss: 0.2383 - binary_accuracy: 0.5000\n",
            "Epoch 66/500\n",
            "1/1 - 0s - loss: 0.2380 - binary_accuracy: 0.5000\n",
            "Epoch 67/500\n",
            "1/1 - 0s - loss: 0.2377 - binary_accuracy: 0.5000\n",
            "Epoch 68/500\n",
            "1/1 - 0s - loss: 0.2374 - binary_accuracy: 0.5000\n",
            "Epoch 69/500\n",
            "1/1 - 0s - loss: 0.2371 - binary_accuracy: 0.5000\n",
            "Epoch 70/500\n",
            "1/1 - 0s - loss: 0.2369 - binary_accuracy: 0.5000\n",
            "Epoch 71/500\n",
            "1/1 - 0s - loss: 0.2366 - binary_accuracy: 0.5000\n",
            "Epoch 72/500\n",
            "1/1 - 0s - loss: 0.2363 - binary_accuracy: 0.5000\n",
            "Epoch 73/500\n",
            "1/1 - 0s - loss: 0.2360 - binary_accuracy: 0.5000\n",
            "Epoch 74/500\n",
            "1/1 - 0s - loss: 0.2357 - binary_accuracy: 0.5000\n",
            "Epoch 75/500\n",
            "1/1 - 0s - loss: 0.2354 - binary_accuracy: 0.5000\n",
            "Epoch 76/500\n",
            "1/1 - 0s - loss: 0.2351 - binary_accuracy: 0.5000\n",
            "Epoch 77/500\n",
            "1/1 - 0s - loss: 0.2348 - binary_accuracy: 0.5000\n",
            "Epoch 78/500\n",
            "1/1 - 0s - loss: 0.2345 - binary_accuracy: 0.5000\n",
            "Epoch 79/500\n",
            "1/1 - 0s - loss: 0.2343 - binary_accuracy: 0.5000\n",
            "Epoch 80/500\n",
            "1/1 - 0s - loss: 0.2340 - binary_accuracy: 0.5000\n",
            "Epoch 81/500\n",
            "1/1 - 0s - loss: 0.2337 - binary_accuracy: 0.5000\n",
            "Epoch 82/500\n",
            "1/1 - 0s - loss: 0.2335 - binary_accuracy: 0.5000\n",
            "Epoch 83/500\n",
            "1/1 - 0s - loss: 0.2332 - binary_accuracy: 0.5000\n",
            "Epoch 84/500\n",
            "1/1 - 0s - loss: 0.2329 - binary_accuracy: 0.5000\n",
            "Epoch 85/500\n",
            "1/1 - 0s - loss: 0.2326 - binary_accuracy: 0.5000\n",
            "Epoch 86/500\n",
            "1/1 - 0s - loss: 0.2324 - binary_accuracy: 0.5000\n",
            "Epoch 87/500\n",
            "1/1 - 0s - loss: 0.2321 - binary_accuracy: 0.5000\n",
            "Epoch 88/500\n",
            "1/1 - 0s - loss: 0.2318 - binary_accuracy: 0.5000\n",
            "Epoch 89/500\n",
            "1/1 - 0s - loss: 0.2315 - binary_accuracy: 0.5000\n",
            "Epoch 90/500\n",
            "1/1 - 0s - loss: 0.2313 - binary_accuracy: 0.5000\n",
            "Epoch 91/500\n",
            "1/1 - 0s - loss: 0.2310 - binary_accuracy: 0.5000\n",
            "Epoch 92/500\n",
            "1/1 - 0s - loss: 0.2307 - binary_accuracy: 0.7500\n",
            "Epoch 93/500\n",
            "1/1 - 0s - loss: 0.2304 - binary_accuracy: 0.7500\n",
            "Epoch 94/500\n",
            "1/1 - 0s - loss: 0.2302 - binary_accuracy: 0.7500\n",
            "Epoch 95/500\n",
            "1/1 - 0s - loss: 0.2299 - binary_accuracy: 0.7500\n",
            "Epoch 96/500\n",
            "1/1 - 0s - loss: 0.2296 - binary_accuracy: 0.7500\n",
            "Epoch 97/500\n",
            "1/1 - 0s - loss: 0.2293 - binary_accuracy: 0.7500\n",
            "Epoch 98/500\n",
            "1/1 - 0s - loss: 0.2290 - binary_accuracy: 0.7500\n",
            "Epoch 99/500\n",
            "1/1 - 0s - loss: 0.2287 - binary_accuracy: 0.7500\n",
            "Epoch 100/500\n",
            "1/1 - 0s - loss: 0.2285 - binary_accuracy: 0.7500\n",
            "Epoch 101/500\n",
            "1/1 - 0s - loss: 0.2282 - binary_accuracy: 0.7500\n",
            "Epoch 102/500\n",
            "1/1 - 0s - loss: 0.2279 - binary_accuracy: 0.7500\n",
            "Epoch 103/500\n",
            "1/1 - 0s - loss: 0.2276 - binary_accuracy: 0.7500\n",
            "Epoch 104/500\n",
            "1/1 - 0s - loss: 0.2273 - binary_accuracy: 0.7500\n",
            "Epoch 105/500\n",
            "1/1 - 0s - loss: 0.2270 - binary_accuracy: 0.7500\n",
            "Epoch 106/500\n",
            "1/1 - 0s - loss: 0.2267 - binary_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "1/1 - 0s - loss: 0.2264 - binary_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "1/1 - 0s - loss: 0.2262 - binary_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "1/1 - 0s - loss: 0.2259 - binary_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "1/1 - 0s - loss: 0.2256 - binary_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "1/1 - 0s - loss: 0.2253 - binary_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "1/1 - 0s - loss: 0.2250 - binary_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "1/1 - 0s - loss: 0.2247 - binary_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "1/1 - 0s - loss: 0.2244 - binary_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "1/1 - 0s - loss: 0.2241 - binary_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "1/1 - 0s - loss: 0.2238 - binary_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "1/1 - 0s - loss: 0.2235 - binary_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "1/1 - 0s - loss: 0.2232 - binary_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "1/1 - 0s - loss: 0.2229 - binary_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "1/1 - 0s - loss: 0.2226 - binary_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "1/1 - 0s - loss: 0.2223 - binary_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "1/1 - 0s - loss: 0.2220 - binary_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "1/1 - 0s - loss: 0.2217 - binary_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "1/1 - 0s - loss: 0.2214 - binary_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "1/1 - 0s - loss: 0.2211 - binary_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "1/1 - 0s - loss: 0.2208 - binary_accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "1/1 - 0s - loss: 0.2205 - binary_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "1/1 - 0s - loss: 0.2202 - binary_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "1/1 - 0s - loss: 0.2199 - binary_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "1/1 - 0s - loss: 0.2196 - binary_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "1/1 - 0s - loss: 0.2192 - binary_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "1/1 - 0s - loss: 0.2189 - binary_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "1/1 - 0s - loss: 0.2186 - binary_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "1/1 - 0s - loss: 0.2183 - binary_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "1/1 - 0s - loss: 0.2180 - binary_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "1/1 - 0s - loss: 0.2177 - binary_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "1/1 - 0s - loss: 0.2174 - binary_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "1/1 - 0s - loss: 0.2171 - binary_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "1/1 - 0s - loss: 0.2168 - binary_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "1/1 - 0s - loss: 0.2165 - binary_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "1/1 - 0s - loss: 0.2162 - binary_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "1/1 - 0s - loss: 0.2159 - binary_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "1/1 - 0s - loss: 0.2155 - binary_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "1/1 - 0s - loss: 0.2152 - binary_accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "1/1 - 0s - loss: 0.2149 - binary_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "1/1 - 0s - loss: 0.2146 - binary_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "1/1 - 0s - loss: 0.2143 - binary_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "1/1 - 0s - loss: 0.2140 - binary_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "1/1 - 0s - loss: 0.2137 - binary_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "1/1 - 0s - loss: 0.2133 - binary_accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "1/1 - 0s - loss: 0.2130 - binary_accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "1/1 - 0s - loss: 0.2127 - binary_accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "1/1 - 0s - loss: 0.2124 - binary_accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "1/1 - 0s - loss: 0.2121 - binary_accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "1/1 - 0s - loss: 0.2118 - binary_accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "1/1 - 0s - loss: 0.2114 - binary_accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "1/1 - 0s - loss: 0.2111 - binary_accuracy: 1.0000\n",
            "Epoch 158/500\n",
            "1/1 - 0s - loss: 0.2108 - binary_accuracy: 1.0000\n",
            "Epoch 159/500\n",
            "1/1 - 0s - loss: 0.2105 - binary_accuracy: 1.0000\n",
            "Epoch 160/500\n",
            "1/1 - 0s - loss: 0.2101 - binary_accuracy: 1.0000\n",
            "Epoch 161/500\n",
            "1/1 - 0s - loss: 0.2098 - binary_accuracy: 1.0000\n",
            "Epoch 162/500\n",
            "1/1 - 0s - loss: 0.2095 - binary_accuracy: 1.0000\n",
            "Epoch 163/500\n",
            "1/1 - 0s - loss: 0.2092 - binary_accuracy: 1.0000\n",
            "Epoch 164/500\n",
            "1/1 - 0s - loss: 0.2088 - binary_accuracy: 1.0000\n",
            "Epoch 165/500\n",
            "1/1 - 0s - loss: 0.2085 - binary_accuracy: 1.0000\n",
            "Epoch 166/500\n",
            "1/1 - 0s - loss: 0.2082 - binary_accuracy: 1.0000\n",
            "Epoch 167/500\n",
            "1/1 - 0s - loss: 0.2078 - binary_accuracy: 1.0000\n",
            "Epoch 168/500\n",
            "1/1 - 0s - loss: 0.2075 - binary_accuracy: 1.0000\n",
            "Epoch 169/500\n",
            "1/1 - 0s - loss: 0.2072 - binary_accuracy: 1.0000\n",
            "Epoch 170/500\n",
            "1/1 - 0s - loss: 0.2068 - binary_accuracy: 1.0000\n",
            "Epoch 171/500\n",
            "1/1 - 0s - loss: 0.2065 - binary_accuracy: 1.0000\n",
            "Epoch 172/500\n",
            "1/1 - 0s - loss: 0.2062 - binary_accuracy: 1.0000\n",
            "Epoch 173/500\n",
            "1/1 - 0s - loss: 0.2058 - binary_accuracy: 1.0000\n",
            "Epoch 174/500\n",
            "1/1 - 0s - loss: 0.2055 - binary_accuracy: 1.0000\n",
            "Epoch 175/500\n",
            "1/1 - 0s - loss: 0.2052 - binary_accuracy: 1.0000\n",
            "Epoch 176/500\n",
            "1/1 - 0s - loss: 0.2049 - binary_accuracy: 1.0000\n",
            "Epoch 177/500\n",
            "1/1 - 0s - loss: 0.2045 - binary_accuracy: 1.0000\n",
            "Epoch 178/500\n",
            "1/1 - 0s - loss: 0.2042 - binary_accuracy: 1.0000\n",
            "Epoch 179/500\n",
            "1/1 - 0s - loss: 0.2039 - binary_accuracy: 1.0000\n",
            "Epoch 180/500\n",
            "1/1 - 0s - loss: 0.2035 - binary_accuracy: 1.0000\n",
            "Epoch 181/500\n",
            "1/1 - 0s - loss: 0.2032 - binary_accuracy: 1.0000\n",
            "Epoch 182/500\n",
            "1/1 - 0s - loss: 0.2028 - binary_accuracy: 1.0000\n",
            "Epoch 183/500\n",
            "1/1 - 0s - loss: 0.2025 - binary_accuracy: 1.0000\n",
            "Epoch 184/500\n",
            "1/1 - 0s - loss: 0.2022 - binary_accuracy: 1.0000\n",
            "Epoch 185/500\n",
            "1/1 - 0s - loss: 0.2018 - binary_accuracy: 1.0000\n",
            "Epoch 186/500\n",
            "1/1 - 0s - loss: 0.2015 - binary_accuracy: 1.0000\n",
            "Epoch 187/500\n",
            "1/1 - 0s - loss: 0.2011 - binary_accuracy: 1.0000\n",
            "Epoch 188/500\n",
            "1/1 - 0s - loss: 0.2008 - binary_accuracy: 1.0000\n",
            "Epoch 189/500\n",
            "1/1 - 0s - loss: 0.2004 - binary_accuracy: 1.0000\n",
            "Epoch 190/500\n",
            "1/1 - 0s - loss: 0.2001 - binary_accuracy: 1.0000\n",
            "Epoch 191/500\n",
            "1/1 - 0s - loss: 0.1997 - binary_accuracy: 1.0000\n",
            "Epoch 192/500\n",
            "1/1 - 0s - loss: 0.1994 - binary_accuracy: 1.0000\n",
            "Epoch 193/500\n",
            "1/1 - 0s - loss: 0.1990 - binary_accuracy: 1.0000\n",
            "Epoch 194/500\n",
            "1/1 - 0s - loss: 0.1987 - binary_accuracy: 1.0000\n",
            "Epoch 195/500\n",
            "1/1 - 0s - loss: 0.1984 - binary_accuracy: 1.0000\n",
            "Epoch 196/500\n",
            "1/1 - 0s - loss: 0.1980 - binary_accuracy: 1.0000\n",
            "Epoch 197/500\n",
            "1/1 - 0s - loss: 0.1977 - binary_accuracy: 1.0000\n",
            "Epoch 198/500\n",
            "1/1 - 0s - loss: 0.1973 - binary_accuracy: 1.0000\n",
            "Epoch 199/500\n",
            "1/1 - 0s - loss: 0.1970 - binary_accuracy: 1.0000\n",
            "Epoch 200/500\n",
            "1/1 - 0s - loss: 0.1966 - binary_accuracy: 1.0000\n",
            "Epoch 201/500\n",
            "1/1 - 0s - loss: 0.1963 - binary_accuracy: 1.0000\n",
            "Epoch 202/500\n",
            "1/1 - 0s - loss: 0.1959 - binary_accuracy: 1.0000\n",
            "Epoch 203/500\n",
            "1/1 - 0s - loss: 0.1955 - binary_accuracy: 1.0000\n",
            "Epoch 204/500\n",
            "1/1 - 0s - loss: 0.1952 - binary_accuracy: 1.0000\n",
            "Epoch 205/500\n",
            "1/1 - 0s - loss: 0.1948 - binary_accuracy: 1.0000\n",
            "Epoch 206/500\n",
            "1/1 - 0s - loss: 0.1945 - binary_accuracy: 1.0000\n",
            "Epoch 207/500\n",
            "1/1 - 0s - loss: 0.1941 - binary_accuracy: 1.0000\n",
            "Epoch 208/500\n",
            "1/1 - 0s - loss: 0.1938 - binary_accuracy: 1.0000\n",
            "Epoch 209/500\n",
            "1/1 - 0s - loss: 0.1934 - binary_accuracy: 1.0000\n",
            "Epoch 210/500\n",
            "1/1 - 0s - loss: 0.1931 - binary_accuracy: 1.0000\n",
            "Epoch 211/500\n",
            "1/1 - 0s - loss: 0.1927 - binary_accuracy: 1.0000\n",
            "Epoch 212/500\n",
            "1/1 - 0s - loss: 0.1924 - binary_accuracy: 1.0000\n",
            "Epoch 213/500\n",
            "1/1 - 0s - loss: 0.1920 - binary_accuracy: 1.0000\n",
            "Epoch 214/500\n",
            "1/1 - 0s - loss: 0.1917 - binary_accuracy: 1.0000\n",
            "Epoch 215/500\n",
            "1/1 - 0s - loss: 0.1913 - binary_accuracy: 1.0000\n",
            "Epoch 216/500\n",
            "1/1 - 0s - loss: 0.1910 - binary_accuracy: 1.0000\n",
            "Epoch 217/500\n",
            "1/1 - 0s - loss: 0.1906 - binary_accuracy: 1.0000\n",
            "Epoch 218/500\n",
            "1/1 - 0s - loss: 0.1903 - binary_accuracy: 1.0000\n",
            "Epoch 219/500\n",
            "1/1 - 0s - loss: 0.1899 - binary_accuracy: 1.0000\n",
            "Epoch 220/500\n",
            "1/1 - 0s - loss: 0.1896 - binary_accuracy: 1.0000\n",
            "Epoch 221/500\n",
            "1/1 - 0s - loss: 0.1892 - binary_accuracy: 1.0000\n",
            "Epoch 222/500\n",
            "1/1 - 0s - loss: 0.1888 - binary_accuracy: 1.0000\n",
            "Epoch 223/500\n",
            "1/1 - 0s - loss: 0.1885 - binary_accuracy: 1.0000\n",
            "Epoch 224/500\n",
            "1/1 - 0s - loss: 0.1881 - binary_accuracy: 1.0000\n",
            "Epoch 225/500\n",
            "1/1 - 0s - loss: 0.1878 - binary_accuracy: 1.0000\n",
            "Epoch 226/500\n",
            "1/1 - 0s - loss: 0.1874 - binary_accuracy: 1.0000\n",
            "Epoch 227/500\n",
            "1/1 - 0s - loss: 0.1871 - binary_accuracy: 1.0000\n",
            "Epoch 228/500\n",
            "1/1 - 0s - loss: 0.1867 - binary_accuracy: 1.0000\n",
            "Epoch 229/500\n",
            "1/1 - 0s - loss: 0.1863 - binary_accuracy: 1.0000\n",
            "Epoch 230/500\n",
            "1/1 - 0s - loss: 0.1860 - binary_accuracy: 1.0000\n",
            "Epoch 231/500\n",
            "1/1 - 0s - loss: 0.1856 - binary_accuracy: 1.0000\n",
            "Epoch 232/500\n",
            "1/1 - 0s - loss: 0.1853 - binary_accuracy: 1.0000\n",
            "Epoch 233/500\n",
            "1/1 - 0s - loss: 0.1849 - binary_accuracy: 1.0000\n",
            "Epoch 234/500\n",
            "1/1 - 0s - loss: 0.1845 - binary_accuracy: 1.0000\n",
            "Epoch 235/500\n",
            "1/1 - 0s - loss: 0.1842 - binary_accuracy: 1.0000\n",
            "Epoch 236/500\n",
            "1/1 - 0s - loss: 0.1838 - binary_accuracy: 1.0000\n",
            "Epoch 237/500\n",
            "1/1 - 0s - loss: 0.1835 - binary_accuracy: 1.0000\n",
            "Epoch 238/500\n",
            "1/1 - 0s - loss: 0.1831 - binary_accuracy: 1.0000\n",
            "Epoch 239/500\n",
            "1/1 - 0s - loss: 0.1827 - binary_accuracy: 1.0000\n",
            "Epoch 240/500\n",
            "1/1 - 0s - loss: 0.1824 - binary_accuracy: 1.0000\n",
            "Epoch 241/500\n",
            "1/1 - 0s - loss: 0.1820 - binary_accuracy: 1.0000\n",
            "Epoch 242/500\n",
            "1/1 - 0s - loss: 0.1816 - binary_accuracy: 1.0000\n",
            "Epoch 243/500\n",
            "1/1 - 0s - loss: 0.1813 - binary_accuracy: 1.0000\n",
            "Epoch 244/500\n",
            "1/1 - 0s - loss: 0.1809 - binary_accuracy: 1.0000\n",
            "Epoch 245/500\n",
            "1/1 - 0s - loss: 0.1805 - binary_accuracy: 1.0000\n",
            "Epoch 246/500\n",
            "1/1 - 0s - loss: 0.1802 - binary_accuracy: 1.0000\n",
            "Epoch 247/500\n",
            "1/1 - 0s - loss: 0.1799 - binary_accuracy: 1.0000\n",
            "Epoch 248/500\n",
            "1/1 - 0s - loss: 0.1795 - binary_accuracy: 1.0000\n",
            "Epoch 249/500\n",
            "1/1 - 0s - loss: 0.1792 - binary_accuracy: 1.0000\n",
            "Epoch 250/500\n",
            "1/1 - 0s - loss: 0.1788 - binary_accuracy: 1.0000\n",
            "Epoch 251/500\n",
            "1/1 - 0s - loss: 0.1785 - binary_accuracy: 1.0000\n",
            "Epoch 252/500\n",
            "1/1 - 0s - loss: 0.1781 - binary_accuracy: 1.0000\n",
            "Epoch 253/500\n",
            "1/1 - 0s - loss: 0.1777 - binary_accuracy: 1.0000\n",
            "Epoch 254/500\n",
            "1/1 - 0s - loss: 0.1773 - binary_accuracy: 1.0000\n",
            "Epoch 255/500\n",
            "1/1 - 0s - loss: 0.1769 - binary_accuracy: 1.0000\n",
            "Epoch 256/500\n",
            "1/1 - 0s - loss: 0.1765 - binary_accuracy: 1.0000\n",
            "Epoch 257/500\n",
            "1/1 - 0s - loss: 0.1761 - binary_accuracy: 1.0000\n",
            "Epoch 258/500\n",
            "1/1 - 0s - loss: 0.1756 - binary_accuracy: 1.0000\n",
            "Epoch 259/500\n",
            "1/1 - 0s - loss: 0.1752 - binary_accuracy: 1.0000\n",
            "Epoch 260/500\n",
            "1/1 - 0s - loss: 0.1748 - binary_accuracy: 1.0000\n",
            "Epoch 261/500\n",
            "1/1 - 0s - loss: 0.1743 - binary_accuracy: 1.0000\n",
            "Epoch 262/500\n",
            "1/1 - 0s - loss: 0.1739 - binary_accuracy: 1.0000\n",
            "Epoch 263/500\n",
            "1/1 - 0s - loss: 0.1734 - binary_accuracy: 1.0000\n",
            "Epoch 264/500\n",
            "1/1 - 0s - loss: 0.1730 - binary_accuracy: 1.0000\n",
            "Epoch 265/500\n",
            "1/1 - 0s - loss: 0.1725 - binary_accuracy: 1.0000\n",
            "Epoch 266/500\n",
            "1/1 - 0s - loss: 0.1721 - binary_accuracy: 1.0000\n",
            "Epoch 267/500\n",
            "1/1 - 0s - loss: 0.1716 - binary_accuracy: 1.0000\n",
            "Epoch 268/500\n",
            "1/1 - 0s - loss: 0.1712 - binary_accuracy: 1.0000\n",
            "Epoch 269/500\n",
            "1/1 - 0s - loss: 0.1707 - binary_accuracy: 1.0000\n",
            "Epoch 270/500\n",
            "1/1 - 0s - loss: 0.1703 - binary_accuracy: 1.0000\n",
            "Epoch 271/500\n",
            "1/1 - 0s - loss: 0.1698 - binary_accuracy: 1.0000\n",
            "Epoch 272/500\n",
            "1/1 - 0s - loss: 0.1694 - binary_accuracy: 1.0000\n",
            "Epoch 273/500\n",
            "1/1 - 0s - loss: 0.1689 - binary_accuracy: 1.0000\n",
            "Epoch 274/500\n",
            "1/1 - 0s - loss: 0.1685 - binary_accuracy: 1.0000\n",
            "Epoch 275/500\n",
            "1/1 - 0s - loss: 0.1680 - binary_accuracy: 1.0000\n",
            "Epoch 276/500\n",
            "1/1 - 0s - loss: 0.1676 - binary_accuracy: 1.0000\n",
            "Epoch 277/500\n",
            "1/1 - 0s - loss: 0.1671 - binary_accuracy: 1.0000\n",
            "Epoch 278/500\n",
            "1/1 - 0s - loss: 0.1667 - binary_accuracy: 1.0000\n",
            "Epoch 279/500\n",
            "1/1 - 0s - loss: 0.1662 - binary_accuracy: 1.0000\n",
            "Epoch 280/500\n",
            "1/1 - 0s - loss: 0.1658 - binary_accuracy: 1.0000\n",
            "Epoch 281/500\n",
            "1/1 - 0s - loss: 0.1653 - binary_accuracy: 1.0000\n",
            "Epoch 282/500\n",
            "1/1 - 0s - loss: 0.1649 - binary_accuracy: 1.0000\n",
            "Epoch 283/500\n",
            "1/1 - 0s - loss: 0.1644 - binary_accuracy: 1.0000\n",
            "Epoch 284/500\n",
            "1/1 - 0s - loss: 0.1640 - binary_accuracy: 1.0000\n",
            "Epoch 285/500\n",
            "1/1 - 0s - loss: 0.1635 - binary_accuracy: 1.0000\n",
            "Epoch 286/500\n",
            "1/1 - 0s - loss: 0.1631 - binary_accuracy: 1.0000\n",
            "Epoch 287/500\n",
            "1/1 - 0s - loss: 0.1627 - binary_accuracy: 1.0000\n",
            "Epoch 288/500\n",
            "1/1 - 0s - loss: 0.1622 - binary_accuracy: 1.0000\n",
            "Epoch 289/500\n",
            "1/1 - 0s - loss: 0.1618 - binary_accuracy: 1.0000\n",
            "Epoch 290/500\n",
            "1/1 - 0s - loss: 0.1613 - binary_accuracy: 1.0000\n",
            "Epoch 291/500\n",
            "1/1 - 0s - loss: 0.1609 - binary_accuracy: 1.0000\n",
            "Epoch 292/500\n",
            "1/1 - 0s - loss: 0.1604 - binary_accuracy: 1.0000\n",
            "Epoch 293/500\n",
            "1/1 - 0s - loss: 0.1600 - binary_accuracy: 1.0000\n",
            "Epoch 294/500\n",
            "1/1 - 0s - loss: 0.1596 - binary_accuracy: 1.0000\n",
            "Epoch 295/500\n",
            "1/1 - 0s - loss: 0.1591 - binary_accuracy: 1.0000\n",
            "Epoch 296/500\n",
            "1/1 - 0s - loss: 0.1587 - binary_accuracy: 1.0000\n",
            "Epoch 297/500\n",
            "1/1 - 0s - loss: 0.1582 - binary_accuracy: 1.0000\n",
            "Epoch 298/500\n",
            "1/1 - 0s - loss: 0.1578 - binary_accuracy: 1.0000\n",
            "Epoch 299/500\n",
            "1/1 - 0s - loss: 0.1574 - binary_accuracy: 1.0000\n",
            "Epoch 300/500\n",
            "1/1 - 0s - loss: 0.1569 - binary_accuracy: 1.0000\n",
            "Epoch 301/500\n",
            "1/1 - 0s - loss: 0.1565 - binary_accuracy: 1.0000\n",
            "Epoch 302/500\n",
            "1/1 - 0s - loss: 0.1560 - binary_accuracy: 1.0000\n",
            "Epoch 303/500\n",
            "1/1 - 0s - loss: 0.1556 - binary_accuracy: 1.0000\n",
            "Epoch 304/500\n",
            "1/1 - 0s - loss: 0.1552 - binary_accuracy: 1.0000\n",
            "Epoch 305/500\n",
            "1/1 - 0s - loss: 0.1547 - binary_accuracy: 1.0000\n",
            "Epoch 306/500\n",
            "1/1 - 0s - loss: 0.1543 - binary_accuracy: 1.0000\n",
            "Epoch 307/500\n",
            "1/1 - 0s - loss: 0.1539 - binary_accuracy: 1.0000\n",
            "Epoch 308/500\n",
            "1/1 - 0s - loss: 0.1534 - binary_accuracy: 1.0000\n",
            "Epoch 309/500\n",
            "1/1 - 0s - loss: 0.1530 - binary_accuracy: 1.0000\n",
            "Epoch 310/500\n",
            "1/1 - 0s - loss: 0.1526 - binary_accuracy: 1.0000\n",
            "Epoch 311/500\n",
            "1/1 - 0s - loss: 0.1521 - binary_accuracy: 1.0000\n",
            "Epoch 312/500\n",
            "1/1 - 0s - loss: 0.1517 - binary_accuracy: 1.0000\n",
            "Epoch 313/500\n",
            "1/1 - 0s - loss: 0.1512 - binary_accuracy: 1.0000\n",
            "Epoch 314/500\n",
            "1/1 - 0s - loss: 0.1508 - binary_accuracy: 1.0000\n",
            "Epoch 315/500\n",
            "1/1 - 0s - loss: 0.1504 - binary_accuracy: 1.0000\n",
            "Epoch 316/500\n",
            "1/1 - 0s - loss: 0.1500 - binary_accuracy: 1.0000\n",
            "Epoch 317/500\n",
            "1/1 - 0s - loss: 0.1495 - binary_accuracy: 1.0000\n",
            "Epoch 318/500\n",
            "1/1 - 0s - loss: 0.1491 - binary_accuracy: 1.0000\n",
            "Epoch 319/500\n",
            "1/1 - 0s - loss: 0.1487 - binary_accuracy: 1.0000\n",
            "Epoch 320/500\n",
            "1/1 - 0s - loss: 0.1482 - binary_accuracy: 1.0000\n",
            "Epoch 321/500\n",
            "1/1 - 0s - loss: 0.1478 - binary_accuracy: 1.0000\n",
            "Epoch 322/500\n",
            "1/1 - 0s - loss: 0.1474 - binary_accuracy: 1.0000\n",
            "Epoch 323/500\n",
            "1/1 - 0s - loss: 0.1469 - binary_accuracy: 1.0000\n",
            "Epoch 324/500\n",
            "1/1 - 0s - loss: 0.1465 - binary_accuracy: 1.0000\n",
            "Epoch 325/500\n",
            "1/1 - 0s - loss: 0.1461 - binary_accuracy: 1.0000\n",
            "Epoch 326/500\n",
            "1/1 - 0s - loss: 0.1457 - binary_accuracy: 1.0000\n",
            "Epoch 327/500\n",
            "1/1 - 0s - loss: 0.1452 - binary_accuracy: 1.0000\n",
            "Epoch 328/500\n",
            "1/1 - 0s - loss: 0.1448 - binary_accuracy: 1.0000\n",
            "Epoch 329/500\n",
            "1/1 - 0s - loss: 0.1444 - binary_accuracy: 1.0000\n",
            "Epoch 330/500\n",
            "1/1 - 0s - loss: 0.1440 - binary_accuracy: 1.0000\n",
            "Epoch 331/500\n",
            "1/1 - 0s - loss: 0.1435 - binary_accuracy: 1.0000\n",
            "Epoch 332/500\n",
            "1/1 - 0s - loss: 0.1431 - binary_accuracy: 1.0000\n",
            "Epoch 333/500\n",
            "1/1 - 0s - loss: 0.1427 - binary_accuracy: 1.0000\n",
            "Epoch 334/500\n",
            "1/1 - 0s - loss: 0.1423 - binary_accuracy: 1.0000\n",
            "Epoch 335/500\n",
            "1/1 - 0s - loss: 0.1418 - binary_accuracy: 1.0000\n",
            "Epoch 336/500\n",
            "1/1 - 0s - loss: 0.1414 - binary_accuracy: 1.0000\n",
            "Epoch 337/500\n",
            "1/1 - 0s - loss: 0.1410 - binary_accuracy: 1.0000\n",
            "Epoch 338/500\n",
            "1/1 - 0s - loss: 0.1406 - binary_accuracy: 1.0000\n",
            "Epoch 339/500\n",
            "1/1 - 0s - loss: 0.1402 - binary_accuracy: 1.0000\n",
            "Epoch 340/500\n",
            "1/1 - 0s - loss: 0.1398 - binary_accuracy: 1.0000\n",
            "Epoch 341/500\n",
            "1/1 - 0s - loss: 0.1393 - binary_accuracy: 1.0000\n",
            "Epoch 342/500\n",
            "1/1 - 0s - loss: 0.1389 - binary_accuracy: 1.0000\n",
            "Epoch 343/500\n",
            "1/1 - 0s - loss: 0.1385 - binary_accuracy: 1.0000\n",
            "Epoch 344/500\n",
            "1/1 - 0s - loss: 0.1381 - binary_accuracy: 1.0000\n",
            "Epoch 345/500\n",
            "1/1 - 0s - loss: 0.1377 - binary_accuracy: 1.0000\n",
            "Epoch 346/500\n",
            "1/1 - 0s - loss: 0.1372 - binary_accuracy: 1.0000\n",
            "Epoch 347/500\n",
            "1/1 - 0s - loss: 0.1368 - binary_accuracy: 1.0000\n",
            "Epoch 348/500\n",
            "1/1 - 0s - loss: 0.1364 - binary_accuracy: 1.0000\n",
            "Epoch 349/500\n",
            "1/1 - 0s - loss: 0.1360 - binary_accuracy: 1.0000\n",
            "Epoch 350/500\n",
            "1/1 - 0s - loss: 0.1356 - binary_accuracy: 1.0000\n",
            "Epoch 351/500\n",
            "1/1 - 0s - loss: 0.1352 - binary_accuracy: 1.0000\n",
            "Epoch 352/500\n",
            "1/1 - 0s - loss: 0.1348 - binary_accuracy: 1.0000\n",
            "Epoch 353/500\n",
            "1/1 - 0s - loss: 0.1344 - binary_accuracy: 1.0000\n",
            "Epoch 354/500\n",
            "1/1 - 0s - loss: 0.1340 - binary_accuracy: 1.0000\n",
            "Epoch 355/500\n",
            "1/1 - 0s - loss: 0.1335 - binary_accuracy: 1.0000\n",
            "Epoch 356/500\n",
            "1/1 - 0s - loss: 0.1331 - binary_accuracy: 1.0000\n",
            "Epoch 357/500\n",
            "1/1 - 0s - loss: 0.1327 - binary_accuracy: 1.0000\n",
            "Epoch 358/500\n",
            "1/1 - 0s - loss: 0.1323 - binary_accuracy: 1.0000\n",
            "Epoch 359/500\n",
            "1/1 - 0s - loss: 0.1319 - binary_accuracy: 1.0000\n",
            "Epoch 360/500\n",
            "1/1 - 0s - loss: 0.1315 - binary_accuracy: 1.0000\n",
            "Epoch 361/500\n",
            "1/1 - 0s - loss: 0.1311 - binary_accuracy: 1.0000\n",
            "Epoch 362/500\n",
            "1/1 - 0s - loss: 0.1307 - binary_accuracy: 1.0000\n",
            "Epoch 363/500\n",
            "1/1 - 0s - loss: 0.1303 - binary_accuracy: 1.0000\n",
            "Epoch 364/500\n",
            "1/1 - 0s - loss: 0.1299 - binary_accuracy: 1.0000\n",
            "Epoch 365/500\n",
            "1/1 - 0s - loss: 0.1295 - binary_accuracy: 1.0000\n",
            "Epoch 366/500\n",
            "1/1 - 0s - loss: 0.1291 - binary_accuracy: 1.0000\n",
            "Epoch 367/500\n",
            "1/1 - 0s - loss: 0.1287 - binary_accuracy: 1.0000\n",
            "Epoch 368/500\n",
            "1/1 - 0s - loss: 0.1283 - binary_accuracy: 1.0000\n",
            "Epoch 369/500\n",
            "1/1 - 0s - loss: 0.1279 - binary_accuracy: 1.0000\n",
            "Epoch 370/500\n",
            "1/1 - 0s - loss: 0.1275 - binary_accuracy: 1.0000\n",
            "Epoch 371/500\n",
            "1/1 - 0s - loss: 0.1271 - binary_accuracy: 1.0000\n",
            "Epoch 372/500\n",
            "1/1 - 0s - loss: 0.1267 - binary_accuracy: 1.0000\n",
            "Epoch 373/500\n",
            "1/1 - 0s - loss: 0.1263 - binary_accuracy: 1.0000\n",
            "Epoch 374/500\n",
            "1/1 - 0s - loss: 0.1259 - binary_accuracy: 1.0000\n",
            "Epoch 375/500\n",
            "1/1 - 0s - loss: 0.1255 - binary_accuracy: 1.0000\n",
            "Epoch 376/500\n",
            "1/1 - 0s - loss: 0.1251 - binary_accuracy: 1.0000\n",
            "Epoch 377/500\n",
            "1/1 - 0s - loss: 0.1247 - binary_accuracy: 1.0000\n",
            "Epoch 378/500\n",
            "1/1 - 0s - loss: 0.1244 - binary_accuracy: 1.0000\n",
            "Epoch 379/500\n",
            "1/1 - 0s - loss: 0.1240 - binary_accuracy: 1.0000\n",
            "Epoch 380/500\n",
            "1/1 - 0s - loss: 0.1236 - binary_accuracy: 1.0000\n",
            "Epoch 381/500\n",
            "1/1 - 0s - loss: 0.1232 - binary_accuracy: 1.0000\n",
            "Epoch 382/500\n",
            "1/1 - 0s - loss: 0.1228 - binary_accuracy: 1.0000\n",
            "Epoch 383/500\n",
            "1/1 - 0s - loss: 0.1224 - binary_accuracy: 1.0000\n",
            "Epoch 384/500\n",
            "1/1 - 0s - loss: 0.1220 - binary_accuracy: 1.0000\n",
            "Epoch 385/500\n",
            "1/1 - 0s - loss: 0.1216 - binary_accuracy: 1.0000\n",
            "Epoch 386/500\n",
            "1/1 - 0s - loss: 0.1213 - binary_accuracy: 1.0000\n",
            "Epoch 387/500\n",
            "1/1 - 0s - loss: 0.1209 - binary_accuracy: 1.0000\n",
            "Epoch 388/500\n",
            "1/1 - 0s - loss: 0.1205 - binary_accuracy: 1.0000\n",
            "Epoch 389/500\n",
            "1/1 - 0s - loss: 0.1201 - binary_accuracy: 1.0000\n",
            "Epoch 390/500\n",
            "1/1 - 0s - loss: 0.1197 - binary_accuracy: 1.0000\n",
            "Epoch 391/500\n",
            "1/1 - 0s - loss: 0.1193 - binary_accuracy: 1.0000\n",
            "Epoch 392/500\n",
            "1/1 - 0s - loss: 0.1190 - binary_accuracy: 1.0000\n",
            "Epoch 393/500\n",
            "1/1 - 0s - loss: 0.1186 - binary_accuracy: 1.0000\n",
            "Epoch 394/500\n",
            "1/1 - 0s - loss: 0.1182 - binary_accuracy: 1.0000\n",
            "Epoch 395/500\n",
            "1/1 - 0s - loss: 0.1178 - binary_accuracy: 1.0000\n",
            "Epoch 396/500\n",
            "1/1 - 0s - loss: 0.1175 - binary_accuracy: 1.0000\n",
            "Epoch 397/500\n",
            "1/1 - 0s - loss: 0.1171 - binary_accuracy: 1.0000\n",
            "Epoch 398/500\n",
            "1/1 - 0s - loss: 0.1167 - binary_accuracy: 1.0000\n",
            "Epoch 399/500\n",
            "1/1 - 0s - loss: 0.1163 - binary_accuracy: 1.0000\n",
            "Epoch 400/500\n",
            "1/1 - 0s - loss: 0.1160 - binary_accuracy: 1.0000\n",
            "Epoch 401/500\n",
            "1/1 - 0s - loss: 0.1156 - binary_accuracy: 1.0000\n",
            "Epoch 402/500\n",
            "1/1 - 0s - loss: 0.1152 - binary_accuracy: 1.0000\n",
            "Epoch 403/500\n",
            "1/1 - 0s - loss: 0.1149 - binary_accuracy: 1.0000\n",
            "Epoch 404/500\n",
            "1/1 - 0s - loss: 0.1145 - binary_accuracy: 1.0000\n",
            "Epoch 405/500\n",
            "1/1 - 0s - loss: 0.1141 - binary_accuracy: 1.0000\n",
            "Epoch 406/500\n",
            "1/1 - 0s - loss: 0.1138 - binary_accuracy: 1.0000\n",
            "Epoch 407/500\n",
            "1/1 - 0s - loss: 0.1134 - binary_accuracy: 1.0000\n",
            "Epoch 408/500\n",
            "1/1 - 0s - loss: 0.1130 - binary_accuracy: 1.0000\n",
            "Epoch 409/500\n",
            "1/1 - 0s - loss: 0.1127 - binary_accuracy: 1.0000\n",
            "Epoch 410/500\n",
            "1/1 - 0s - loss: 0.1123 - binary_accuracy: 1.0000\n",
            "Epoch 411/500\n",
            "1/1 - 0s - loss: 0.1120 - binary_accuracy: 1.0000\n",
            "Epoch 412/500\n",
            "1/1 - 0s - loss: 0.1116 - binary_accuracy: 1.0000\n",
            "Epoch 413/500\n",
            "1/1 - 0s - loss: 0.1112 - binary_accuracy: 1.0000\n",
            "Epoch 414/500\n",
            "1/1 - 0s - loss: 0.1109 - binary_accuracy: 1.0000\n",
            "Epoch 415/500\n",
            "1/1 - 0s - loss: 0.1105 - binary_accuracy: 1.0000\n",
            "Epoch 416/500\n",
            "1/1 - 0s - loss: 0.1102 - binary_accuracy: 1.0000\n",
            "Epoch 417/500\n",
            "1/1 - 0s - loss: 0.1098 - binary_accuracy: 1.0000\n",
            "Epoch 418/500\n",
            "1/1 - 0s - loss: 0.1094 - binary_accuracy: 1.0000\n",
            "Epoch 419/500\n",
            "1/1 - 0s - loss: 0.1091 - binary_accuracy: 1.0000\n",
            "Epoch 420/500\n",
            "1/1 - 0s - loss: 0.1088 - binary_accuracy: 1.0000\n",
            "Epoch 421/500\n",
            "1/1 - 0s - loss: 0.1084 - binary_accuracy: 1.0000\n",
            "Epoch 422/500\n",
            "1/1 - 0s - loss: 0.1080 - binary_accuracy: 1.0000\n",
            "Epoch 423/500\n",
            "1/1 - 0s - loss: 0.1077 - binary_accuracy: 1.0000\n",
            "Epoch 424/500\n",
            "1/1 - 0s - loss: 0.1073 - binary_accuracy: 1.0000\n",
            "Epoch 425/500\n",
            "1/1 - 0s - loss: 0.1070 - binary_accuracy: 1.0000\n",
            "Epoch 426/500\n",
            "1/1 - 0s - loss: 0.1066 - binary_accuracy: 1.0000\n",
            "Epoch 427/500\n",
            "1/1 - 0s - loss: 0.1063 - binary_accuracy: 1.0000\n",
            "Epoch 428/500\n",
            "1/1 - 0s - loss: 0.1060 - binary_accuracy: 1.0000\n",
            "Epoch 429/500\n",
            "1/1 - 0s - loss: 0.1056 - binary_accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "1/1 - 0s - loss: 0.1053 - binary_accuracy: 1.0000\n",
            "Epoch 431/500\n",
            "1/1 - 0s - loss: 0.1049 - binary_accuracy: 1.0000\n",
            "Epoch 432/500\n",
            "1/1 - 0s - loss: 0.1046 - binary_accuracy: 1.0000\n",
            "Epoch 433/500\n",
            "1/1 - 0s - loss: 0.1042 - binary_accuracy: 1.0000\n",
            "Epoch 434/500\n",
            "1/1 - 0s - loss: 0.1039 - binary_accuracy: 1.0000\n",
            "Epoch 435/500\n",
            "1/1 - 0s - loss: 0.1036 - binary_accuracy: 1.0000\n",
            "Epoch 436/500\n",
            "1/1 - 0s - loss: 0.1032 - binary_accuracy: 1.0000\n",
            "Epoch 437/500\n",
            "1/1 - 0s - loss: 0.1029 - binary_accuracy: 1.0000\n",
            "Epoch 438/500\n",
            "1/1 - 0s - loss: 0.1026 - binary_accuracy: 1.0000\n",
            "Epoch 439/500\n",
            "1/1 - 0s - loss: 0.1022 - binary_accuracy: 1.0000\n",
            "Epoch 440/500\n",
            "1/1 - 0s - loss: 0.1019 - binary_accuracy: 1.0000\n",
            "Epoch 441/500\n",
            "1/1 - 0s - loss: 0.1016 - binary_accuracy: 1.0000\n",
            "Epoch 442/500\n",
            "1/1 - 0s - loss: 0.1012 - binary_accuracy: 1.0000\n",
            "Epoch 443/500\n",
            "1/1 - 0s - loss: 0.1009 - binary_accuracy: 1.0000\n",
            "Epoch 444/500\n",
            "1/1 - 0s - loss: 0.1006 - binary_accuracy: 1.0000\n",
            "Epoch 445/500\n",
            "1/1 - 0s - loss: 0.1003 - binary_accuracy: 1.0000\n",
            "Epoch 446/500\n",
            "1/1 - 0s - loss: 0.0999 - binary_accuracy: 1.0000\n",
            "Epoch 447/500\n",
            "1/1 - 0s - loss: 0.0996 - binary_accuracy: 1.0000\n",
            "Epoch 448/500\n",
            "1/1 - 0s - loss: 0.0993 - binary_accuracy: 1.0000\n",
            "Epoch 449/500\n",
            "1/1 - 0s - loss: 0.0990 - binary_accuracy: 1.0000\n",
            "Epoch 450/500\n",
            "1/1 - 0s - loss: 0.0986 - binary_accuracy: 1.0000\n",
            "Epoch 451/500\n",
            "1/1 - 0s - loss: 0.0983 - binary_accuracy: 1.0000\n",
            "Epoch 452/500\n",
            "1/1 - 0s - loss: 0.0980 - binary_accuracy: 1.0000\n",
            "Epoch 453/500\n",
            "1/1 - 0s - loss: 0.0977 - binary_accuracy: 1.0000\n",
            "Epoch 454/500\n",
            "1/1 - 0s - loss: 0.0974 - binary_accuracy: 1.0000\n",
            "Epoch 455/500\n",
            "1/1 - 0s - loss: 0.0970 - binary_accuracy: 1.0000\n",
            "Epoch 456/500\n",
            "1/1 - 0s - loss: 0.0967 - binary_accuracy: 1.0000\n",
            "Epoch 457/500\n",
            "1/1 - 0s - loss: 0.0964 - binary_accuracy: 1.0000\n",
            "Epoch 458/500\n",
            "1/1 - 0s - loss: 0.0961 - binary_accuracy: 1.0000\n",
            "Epoch 459/500\n",
            "1/1 - 0s - loss: 0.0958 - binary_accuracy: 1.0000\n",
            "Epoch 460/500\n",
            "1/1 - 0s - loss: 0.0955 - binary_accuracy: 1.0000\n",
            "Epoch 461/500\n",
            "1/1 - 0s - loss: 0.0952 - binary_accuracy: 1.0000\n",
            "Epoch 462/500\n",
            "1/1 - 0s - loss: 0.0948 - binary_accuracy: 1.0000\n",
            "Epoch 463/500\n",
            "1/1 - 0s - loss: 0.0945 - binary_accuracy: 1.0000\n",
            "Epoch 464/500\n",
            "1/1 - 0s - loss: 0.0942 - binary_accuracy: 1.0000\n",
            "Epoch 465/500\n",
            "1/1 - 0s - loss: 0.0939 - binary_accuracy: 1.0000\n",
            "Epoch 466/500\n",
            "1/1 - 0s - loss: 0.0936 - binary_accuracy: 1.0000\n",
            "Epoch 467/500\n",
            "1/1 - 0s - loss: 0.0933 - binary_accuracy: 1.0000\n",
            "Epoch 468/500\n",
            "1/1 - 0s - loss: 0.0930 - binary_accuracy: 1.0000\n",
            "Epoch 469/500\n",
            "1/1 - 0s - loss: 0.0927 - binary_accuracy: 1.0000\n",
            "Epoch 470/500\n",
            "1/1 - 0s - loss: 0.0924 - binary_accuracy: 1.0000\n",
            "Epoch 471/500\n",
            "1/1 - 0s - loss: 0.0921 - binary_accuracy: 1.0000\n",
            "Epoch 472/500\n",
            "1/1 - 0s - loss: 0.0918 - binary_accuracy: 1.0000\n",
            "Epoch 473/500\n",
            "1/1 - 0s - loss: 0.0915 - binary_accuracy: 1.0000\n",
            "Epoch 474/500\n",
            "1/1 - 0s - loss: 0.0912 - binary_accuracy: 1.0000\n",
            "Epoch 475/500\n",
            "1/1 - 0s - loss: 0.0909 - binary_accuracy: 1.0000\n",
            "Epoch 476/500\n",
            "1/1 - 0s - loss: 0.0906 - binary_accuracy: 1.0000\n",
            "Epoch 477/500\n",
            "1/1 - 0s - loss: 0.0903 - binary_accuracy: 1.0000\n",
            "Epoch 478/500\n",
            "1/1 - 0s - loss: 0.0900 - binary_accuracy: 1.0000\n",
            "Epoch 479/500\n",
            "1/1 - 0s - loss: 0.0897 - binary_accuracy: 1.0000\n",
            "Epoch 480/500\n",
            "1/1 - 0s - loss: 0.0894 - binary_accuracy: 1.0000\n",
            "Epoch 481/500\n",
            "1/1 - 0s - loss: 0.0891 - binary_accuracy: 1.0000\n",
            "Epoch 482/500\n",
            "1/1 - 0s - loss: 0.0888 - binary_accuracy: 1.0000\n",
            "Epoch 483/500\n",
            "1/1 - 0s - loss: 0.0885 - binary_accuracy: 1.0000\n",
            "Epoch 484/500\n",
            "1/1 - 0s - loss: 0.0882 - binary_accuracy: 1.0000\n",
            "Epoch 485/500\n",
            "1/1 - 0s - loss: 0.0880 - binary_accuracy: 1.0000\n",
            "Epoch 486/500\n",
            "1/1 - 0s - loss: 0.0877 - binary_accuracy: 1.0000\n",
            "Epoch 487/500\n",
            "1/1 - 0s - loss: 0.0874 - binary_accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "1/1 - 0s - loss: 0.0871 - binary_accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "1/1 - 0s - loss: 0.0868 - binary_accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "1/1 - 0s - loss: 0.0865 - binary_accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "1/1 - 0s - loss: 0.0863 - binary_accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "1/1 - 0s - loss: 0.0860 - binary_accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "1/1 - 0s - loss: 0.0857 - binary_accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "1/1 - 0s - loss: 0.0854 - binary_accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "1/1 - 0s - loss: 0.0851 - binary_accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "1/1 - 0s - loss: 0.0849 - binary_accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "1/1 - 0s - loss: 0.0846 - binary_accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "1/1 - 0s - loss: 0.0843 - binary_accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "1/1 - 0s - loss: 0.0840 - binary_accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "1/1 - 0s - loss: 0.0838 - binary_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2c1ec966d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bflJ7aN6qpT3",
        "outputId": "1ec7a6b1-35ad-480b-907c-c3abc605b1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(model.predict(X))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.3763654 ]\n",
            " [0.7490106 ]\n",
            " [0.74157757]\n",
            " [0.25008917]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZA48q48gZpZ",
        "outputId": "1a135126-0a31-4e9b-b0df-6db91c49977e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(model.predict(X).round())"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xEiL-1LdK5-"
      },
      "source": [
        "# Example 2: ANN to learn to XOR function\n",
        "\n",
        "This second exxample solves the same XOR problem, but with a somewhat different architecture. \n",
        "\n",
        "Note that using Dense(activation='relu') is equivalent to first add a Dense layer and then add Activation('relu')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrVo8gwwcFo7"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "import numpy as np\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "sgd = SGD(lr=0.1)\n",
        "model.compile(loss='binary_crossentropy', optimizer=sgd)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8fhAmSlhJea",
        "outputId": "d32ebaae-e5ec-4f00-8482-3dc2c189f5f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_17 (Dense)             (None, 8)                 24        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 9         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 33\n",
            "Trainable params: 33\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wheNml6liX-i"
      },
      "source": [
        "from IPython.display import SVG, display\n",
        "def show_svg():\n",
        "    display(SVG(url='http://upload.wikimedia.org/wikipedia/en/a/a4/Flag_of_the_United_States.svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S8v14T_i9p_",
        "outputId": "280e2ea0-cc90-4e29-bd22-48badb377026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        }
      },
      "source": [
        "%%html\n",
        "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1400\" height=\"800\" style=\"cursor: move;\"><g transform=\"translate(31.029124448207995,22.95774483714024) scale(0.9619274546647754)\"><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,250\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,290\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,330\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,370\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,410\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,450\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,250\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,290\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,330\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,370\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,410\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,450\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,250, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,290, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,330, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,370, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,410, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,450, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,490\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,530\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,490\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,530\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,490, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,530, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><circle r=\"10\" class=\"node\" id=\"0_0\" cx=\"540\" cy=\"370\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"0_1\" cx=\"540\" cy=\"410\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_0\" cx=\"720\" cy=\"250\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_1\" cx=\"720\" cy=\"290\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_2\" cx=\"720\" cy=\"330\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_3\" cx=\"720\" cy=\"370\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_4\" cx=\"720\" cy=\"410\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_5\" cx=\"720\" cy=\"450\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_6\" cx=\"720\" cy=\"490\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_7\" cx=\"720\" cy=\"530\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"2_0\" cx=\"900\" cy=\"390\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><text class=\"text\" dy=\".35em\" x=\"505\" y=\"570\" style=\"font-size: 12px;\">Input Layer ∈ ℝ²</text><text class=\"text\" dy=\".35em\" x=\"685\" y=\"570\" style=\"font-size: 12px;\">Hidden Layer ∈ ℝ⁸</text><text class=\"text\" dy=\".35em\" x=\"865\" y=\"570\" style=\"font-size: 12px;\">Output Layer ∈ ℝ¹</text></g><defs><marker id=\"arrow\" viewBox=\"0 -5 10 10\" markerWidth=\"7\" markerHeight=\"7\" orient=\"auto\" refX=\"40\"><path d=\"M0,-5L10,0L0,5\" style=\"stroke: rgb(80, 80, 80); fill: none;\"></path></marker></defs></svg>"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1400\" height=\"800\" style=\"cursor: move;\"><g transform=\"translate(31.029124448207995,22.95774483714024) scale(0.9619274546647754)\"><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,250\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,290\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,330\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,370\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,410\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,450\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,250\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,290\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,330\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,370\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,410\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,450\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,250, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,290, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,330, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,370, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,410, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,450, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,490\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,370, 720,530\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,490\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M540,410, 720,530\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,490, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><path class=\"link\" marker-end=\"\" d=\"M720,530, 900,390\" style=\"stroke-width: 0.5; stroke-opacity: 1; stroke: rgb(80, 80, 80);\"></path><circle r=\"10\" class=\"node\" id=\"0_0\" cx=\"540\" cy=\"370\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"0_1\" cx=\"540\" cy=\"410\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_0\" cx=\"720\" cy=\"250\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_1\" cx=\"720\" cy=\"290\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_2\" cx=\"720\" cy=\"330\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_3\" cx=\"720\" cy=\"370\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_4\" cx=\"720\" cy=\"410\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_5\" cx=\"720\" cy=\"450\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_6\" cx=\"720\" cy=\"490\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"1_7\" cx=\"720\" cy=\"530\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"10\" class=\"node\" id=\"2_0\" cx=\"900\" cy=\"390\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><text class=\"text\" dy=\".35em\" x=\"505\" y=\"570\" style=\"font-size: 12px;\">Input Layer ∈ ℝ²</text><text class=\"text\" dy=\".35em\" x=\"685\" y=\"570\" style=\"font-size: 12px;\">Hidden Layer ∈ ℝ⁸</text><text class=\"text\" dy=\".35em\" x=\"865\" y=\"570\" style=\"font-size: 12px;\">Output Layer ∈ ℝ¹</text></g><defs><marker id=\"arrow\" viewBox=\"0 -5 10 10\" markerWidth=\"7\" markerHeight=\"7\" orient=\"auto\" refX=\"40\"><path d=\"M0,-5L10,0L0,5\" style=\"stroke: rgb(80, 80, 80); fill: none;\"></path></marker></defs></svg>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zy9UZVMhL6Z",
        "outputId": "c436be04-ab00-4f28-c2bb-30e63779a89b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "model.fit(X, y, batch_size=1, epochs=100)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6823\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.6783\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6693\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6645\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.6561\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.6553\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.6456\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6467\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.6387\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6361\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6301\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6238\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6202\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.6135\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6072\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5997\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.6056\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5940\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5887\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5840\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5769\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5739\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5663\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5620\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5512\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5618\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5470\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5386\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5383\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5338\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5269\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.5146\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5216\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5140\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5012\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.5026\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.4952\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4869\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4815\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4751\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4668\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4676\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4554\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.4467\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4450\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4309\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4286\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4178\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4179\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3973\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4046\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3878\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3766\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3736\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3655\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3512\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3543\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3320\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3381\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3268\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3180\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3049\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2910\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3032\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2779\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2800\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2692\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2706\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2562\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2503\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2419\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2364\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2236\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2269\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2175\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2140\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2062\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2047\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1944\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1930\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1862\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1826\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1800\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1752\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1685\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1670\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1614\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1576\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1540\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1548\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1496\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1436\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1435\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1383\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1357\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1332\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1299\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1315\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1246\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2c1541c5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MamdOxY0orsd",
        "outputId": "68c39f98-dbff-43bb-9d44-5b2fda93acd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(model.predict(X))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.15989205]\n",
            " [0.95116425]\n",
            " [0.9294722 ]\n",
            " [0.16591695]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "832BAOFphUjL",
        "outputId": "2e94c547-6aa9-4275-96f1-69f119fe17ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(model.predict_proba(X))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.47304463]\n",
            " [0.9623261 ]\n",
            " [0.483178  ]\n",
            " [0.06027541]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeGFSaXKptNR"
      },
      "source": [
        "# Example: simpler model for the XOR problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O63XkPaepxiY"
      },
      "source": [
        " from keras.models import Sequential\n",
        " from keras.layers.core import Dense, Dropout, Activation\n",
        " from keras.optimizers import SGD\n",
        " import numpy as np\n",
        " \n",
        " X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        " y = np.array([[0],[1],[1],[0]])\n",
        " \n",
        " model = Sequential()\n",
        " model.add(Dense(2, input_dim=2))\n",
        " model.add(Activation('tanh'))\n",
        " model.add(Dense(1))\n",
        " model.add(Activation('sigmoid'))\n",
        " \n",
        " sgd = SGD(lr=0.1)\n",
        " model.compile(loss='mean_squared_error', optimizer=sgd)\n",
        " \n",
        " model.fit(X, y, batch_size=1, epochs=1000)\n",
        " print(model.predict_proba(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSx9hQBareKA"
      },
      "source": [
        "# Ploting learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3oF8V38rkiL",
        "outputId": "1b93d8f8-912c-47b1-c200-651f9034efc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " from keras.models import Sequential\n",
        " from keras.layers.core import Dense, Dropout, Activation\n",
        " from keras.optimizers import SGD\n",
        " import numpy as np\n",
        " \n",
        " X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        " y = np.array([[0],[1],[1],[0]])\n",
        " \n",
        " model = Sequential()\n",
        " model.add(Dense(2, input_dim=2))\n",
        " model.add(Activation('tanh'))\n",
        " model.add(Dense(1))\n",
        " model.add(Activation('sigmoid'))\n",
        " \n",
        " sgd = SGD(lr=0.1)\n",
        " model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['acc'])\n",
        " \n",
        " history = model.fit(X, y, batch_size=1, epochs=100)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2553 - acc: 0.2500\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2550 - acc: 0.5000\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2545 - acc: 0.5000\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2542 - acc: 0.5000\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2539 - acc: 0.5000\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2536 - acc: 0.7500\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2533 - acc: 0.7500\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2529 - acc: 0.5000\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2526 - acc: 0.5000\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2523 - acc: 0.5000\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2520 - acc: 0.5000\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2515 - acc: 0.7500\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2512 - acc: 0.7500\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2509 - acc: 0.5000\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2507 - acc: 0.5000\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2504 - acc: 0.5000\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2501 - acc: 0.7500\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2497 - acc: 0.7500\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2494 - acc: 0.5000\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2491 - acc: 0.7500\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2488 - acc: 0.7500\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2485 - acc: 0.7500\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2481 - acc: 0.5000\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2478 - acc: 0.5000\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2476 - acc: 0.7500\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2471 - acc: 0.7500\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2468 - acc: 0.7500\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2466 - acc: 0.7500\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2463 - acc: 0.7500\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2460 - acc: 0.7500\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2456 - acc: 0.7500\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2453 - acc: 0.7500\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2450 - acc: 0.7500\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2446 - acc: 0.7500\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2442 - acc: 0.7500\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2440 - acc: 0.7500\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2437 - acc: 0.7500\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2432 - acc: 0.7500\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2429 - acc: 0.7500\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2427 - acc: 0.7500\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2423 - acc: 0.7500\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2420 - acc: 0.7500\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2416 - acc: 0.7500\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2413 - acc: 0.7500\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2409 - acc: 0.7500\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2406 - acc: 0.7500\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2402 - acc: 0.7500\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2400 - acc: 0.7500\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2395 - acc: 0.7500\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2392 - acc: 0.7500\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2388 - acc: 0.7500\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2384 - acc: 0.7500\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2381 - acc: 0.7500\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2378 - acc: 0.7500\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2374 - acc: 0.7500\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2371 - acc: 0.7500\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2366 - acc: 0.7500\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2363 - acc: 0.7500\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2359 - acc: 0.7500\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2356 - acc: 0.7500\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2352 - acc: 0.7500\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2348 - acc: 0.7500\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2344 - acc: 0.7500\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2341 - acc: 0.7500\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2337 - acc: 0.7500\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2333 - acc: 0.7500\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2329 - acc: 0.7500\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2325 - acc: 0.7500\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2321 - acc: 0.7500\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2317 - acc: 0.7500\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2314 - acc: 0.7500\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2310 - acc: 0.7500\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2306 - acc: 0.7500\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2302 - acc: 0.7500\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2298 - acc: 0.7500\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2294 - acc: 0.7500\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2290 - acc: 0.7500\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2286 - acc: 0.7500\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2282 - acc: 0.7500\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2278 - acc: 0.7500\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2275 - acc: 0.7500\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2270 - acc: 0.7500\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2266 - acc: 0.7500\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2262 - acc: 0.7500\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2258 - acc: 0.7500\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2255 - acc: 0.7500\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2250 - acc: 0.7500\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2247 - acc: 0.7500\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2243 - acc: 0.7500\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2238 - acc: 0.7500\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2235 - acc: 0.7500\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2230 - acc: 0.7500\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2227 - acc: 0.7500\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2222 - acc: 0.7500\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2218 - acc: 0.7500\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2215 - acc: 0.7500\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2211 - acc: 0.7500\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2207 - acc: 0.7500\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2203 - acc: 0.7500\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2199 - acc: 0.7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umxEq6l6rTaO",
        "outputId": "e20f575a-2948-4060-8c8e-05b9e49cbb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5aFlE4osNu7",
        "outputId": "febf9e9d-2315-4c76-ce2b-107cac65f55b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgq6G33ipobE"
      },
      "source": [
        "# Example: ANN trained on the Digits dataset\n",
        "\n",
        "In this example, we train a neural network on the [Digits dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dnGceA6teox",
        "outputId": "3866800f-2767-48da-d188-695aa9929889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "dig = load_digits()\n",
        "print(dig.data.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "plt.gray() \n",
        "plt.matshow(dig.images[42]) \n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1797, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBqEI_qXbftv",
        "outputId": "05469fe4-a1bb-448e-9847-c955dc18afd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import RMSprop, Adadelta, Adam\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dig = load_digits()\n",
        "onehot_target = pd.get_dummies(dig.target)\n",
        "x_train, x_val, y_train, y_val = train_test_split(dig.data, onehot_target, test_size=0.1, random_state=20)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=x_train.shape[1], activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=Adadelta(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "model.fit(x_train, y_train, epochs=50, batch_size=64)\n",
        "\n",
        "scores = model.evaluate(x_val, y_val)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_41 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 26,122\n",
            "Trainable params: 26,122\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.0033 - categorical_accuracy: 0.0414\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.9335 - categorical_accuracy: 0.0396\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.8646 - categorical_accuracy: 0.0377\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.7965 - categorical_accuracy: 0.0377\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.7293 - categorical_accuracy: 0.0371\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.6628 - categorical_accuracy: 0.0371\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.5977 - categorical_accuracy: 0.0359\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.5341 - categorical_accuracy: 0.0353\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.4711 - categorical_accuracy: 0.0359\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 6.4088 - categorical_accuracy: 0.0365\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.3480 - categorical_accuracy: 0.0371\n",
            "Epoch 12/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.2874 - categorical_accuracy: 0.0371\n",
            "Epoch 13/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.2278 - categorical_accuracy: 0.0359\n",
            "Epoch 14/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.1691 - categorical_accuracy: 0.0365\n",
            "Epoch 15/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.1114 - categorical_accuracy: 0.0365\n",
            "Epoch 16/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.0542 - categorical_accuracy: 0.0377\n",
            "Epoch 17/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.9980 - categorical_accuracy: 0.0377\n",
            "Epoch 18/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.9425 - categorical_accuracy: 0.0371\n",
            "Epoch 19/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.8882 - categorical_accuracy: 0.0371\n",
            "Epoch 20/50\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 5.8344 - categorical_accuracy: 0.0371\n",
            "Epoch 21/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.7816 - categorical_accuracy: 0.0371\n",
            "Epoch 22/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.7300 - categorical_accuracy: 0.0383\n",
            "Epoch 23/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.6786 - categorical_accuracy: 0.0377\n",
            "Epoch 24/50\n",
            "26/26 [==============================] - 0s 1ms/step - loss: 5.6278 - categorical_accuracy: 0.0390\n",
            "Epoch 25/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.5785 - categorical_accuracy: 0.0408\n",
            "Epoch 26/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.5293 - categorical_accuracy: 0.0414\n",
            "Epoch 27/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.4810 - categorical_accuracy: 0.0427\n",
            "Epoch 28/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.4330 - categorical_accuracy: 0.0439\n",
            "Epoch 29/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.3858 - categorical_accuracy: 0.0445\n",
            "Epoch 30/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.3395 - categorical_accuracy: 0.0439\n",
            "Epoch 31/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.2944 - categorical_accuracy: 0.0445\n",
            "Epoch 32/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.2493 - categorical_accuracy: 0.0489\n",
            "Epoch 33/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.2049 - categorical_accuracy: 0.0501\n",
            "Epoch 34/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1613 - categorical_accuracy: 0.0526\n",
            "Epoch 35/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1184 - categorical_accuracy: 0.0550\n",
            "Epoch 36/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.0762 - categorical_accuracy: 0.0557\n",
            "Epoch 37/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.0347 - categorical_accuracy: 0.0569\n",
            "Epoch 38/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.9936 - categorical_accuracy: 0.0575\n",
            "Epoch 39/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.9532 - categorical_accuracy: 0.0594\n",
            "Epoch 40/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.9129 - categorical_accuracy: 0.0600\n",
            "Epoch 41/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.8733 - categorical_accuracy: 0.0618\n",
            "Epoch 42/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.8342 - categorical_accuracy: 0.0643\n",
            "Epoch 43/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.7958 - categorical_accuracy: 0.0662\n",
            "Epoch 44/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.7577 - categorical_accuracy: 0.0668\n",
            "Epoch 45/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.7202 - categorical_accuracy: 0.0693\n",
            "Epoch 46/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.6831 - categorical_accuracy: 0.0711\n",
            "Epoch 47/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.6467 - categorical_accuracy: 0.0717\n",
            "Epoch 48/50\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.6109 - categorical_accuracy: 0.0736\n",
            "Epoch 49/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.5748 - categorical_accuracy: 0.0773\n",
            "Epoch 50/50\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.5394 - categorical_accuracy: 0.0785\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 4.6139 - categorical_accuracy: 0.0833\n",
            "\n",
            "categorical_accuracy: 8.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pAv-bbD8Y6Z"
      },
      "source": [
        "# Example: Comparing ANN and SVC on the Digits dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddZzSPHKvC9_",
        "outputId": "df7b8d10-58d7-4d40-f453-8fd6690a5ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy\n",
        "import pandas\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import zero_one_loss\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "\n",
        "dataset = load_digits()\n",
        "\n",
        "X = dataset[\"data\"]\n",
        "y = dataset[\"target\"]\n",
        "y_indicators = pandas.get_dummies(y).values\n",
        "\n",
        "# Center each feature and scale the variance to be unitary\n",
        "X = preprocessing.scale(X)\n",
        "\n",
        "svc = SVC(gamma=0.001)\n",
        "\n",
        "# Set up variables\n",
        "svc_error = 0\n",
        "ann_error = 0\n",
        "n_folds = 10\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "for train_inds, test_inds in kf.split(X):\n",
        "    X_train, X_test = X[train_inds], X[test_inds]\n",
        "    y_train, y_test = y[train_inds], y[test_inds]\n",
        "    y_train_indicators, y_test_indicators = y_indicators[train_inds, :], y_indicators[test_inds, :]\n",
        "\n",
        "    # Use SVM\n",
        "    svc.fit(X_train, y_train)\n",
        "    y_pred = svc.predict(X_test)\n",
        "    svc_error += zero_one_loss(y_test, y_pred)\n",
        "\n",
        "    # Use deep learner\n",
        "    ann = Sequential()\n",
        "    ann.add(Dense(256, input_dim=X.shape[1], kernel_initializer=\"glorot_uniform\"))\n",
        "    ann.add(Activation(\"relu\"))\n",
        "    ann.add(Dense(10, kernel_initializer=\"glorot_uniform\"))\n",
        "    ann.add(Activation(\"sigmoid\"))\n",
        "    ann.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
        "\n",
        "    ann.fit(X_train, y_train_indicators, epochs=50, batch_size=32)\n",
        "    y_pred = ann.predict(X_test)\n",
        "    # The predicted class is the output response with the largest value\n",
        "    y_pred = numpy.argmax(y_pred, 1)\n",
        "    ann_error += zero_one_loss(y_test, y_pred)\n",
        "\n",
        "print(svc_error/n_folds)\n",
        "print(ann_error/n_folds)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 2.1895\n",
            "Epoch 2/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 2.0350\n",
            "Epoch 3/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.9101\n",
            "Epoch 4/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.7926\n",
            "Epoch 5/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.6736\n",
            "Epoch 6/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.5505\n",
            "Epoch 7/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.4237\n",
            "Epoch 8/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2962\n",
            "Epoch 9/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.1716\n",
            "Epoch 10/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.0531\n",
            "Epoch 11/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.9434\n",
            "Epoch 12/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.8446\n",
            "Epoch 13/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.7568\n",
            "Epoch 14/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.6801\n",
            "Epoch 15/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.6135\n",
            "Epoch 16/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.5562\n",
            "Epoch 17/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.5069\n",
            "Epoch 18/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4643\n",
            "Epoch 19/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4277\n",
            "Epoch 20/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3959\n",
            "Epoch 21/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3682\n",
            "Epoch 22/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3439\n",
            "Epoch 23/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3225\n",
            "Epoch 24/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3035\n",
            "Epoch 25/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2867\n",
            "Epoch 26/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2716\n",
            "Epoch 27/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2579\n",
            "Epoch 28/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2455\n",
            "Epoch 29/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2343\n",
            "Epoch 30/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2241\n",
            "Epoch 31/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2147\n",
            "Epoch 32/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2060\n",
            "Epoch 33/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1981\n",
            "Epoch 34/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1907\n",
            "Epoch 35/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1838\n",
            "Epoch 36/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1774\n",
            "Epoch 37/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1714\n",
            "Epoch 38/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1658\n",
            "Epoch 39/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1606\n",
            "Epoch 40/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1556\n",
            "Epoch 41/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1510\n",
            "Epoch 42/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1467\n",
            "Epoch 43/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1425\n",
            "Epoch 44/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1386\n",
            "Epoch 45/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1349\n",
            "Epoch 46/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1313\n",
            "Epoch 47/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1280\n",
            "Epoch 48/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1248\n",
            "Epoch 49/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1217\n",
            "Epoch 50/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1188\n",
            "WARNING:tensorflow:7 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2c25932048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Epoch 1/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 2.1820\n",
            "Epoch 2/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 2.0163\n",
            "Epoch 3/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.8910\n",
            "Epoch 4/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.7776\n",
            "Epoch 5/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.6644\n",
            "Epoch 6/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.5466\n",
            "Epoch 7/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.4225\n",
            "Epoch 8/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.2943\n",
            "Epoch 9/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.1669\n",
            "Epoch 10/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.0451\n",
            "Epoch 11/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.9327\n",
            "Epoch 12/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.8317\n",
            "Epoch 13/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.7428\n",
            "Epoch 14/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.6659\n",
            "Epoch 15/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.5996\n",
            "Epoch 16/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.5429\n",
            "Epoch 17/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4943\n",
            "Epoch 18/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4525\n",
            "Epoch 19/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.4165\n",
            "Epoch 20/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3853\n",
            "Epoch 21/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3581\n",
            "Epoch 22/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3342\n",
            "Epoch 23/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3132\n",
            "Epoch 24/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2946\n",
            "Epoch 25/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2778\n",
            "Epoch 26/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2629\n",
            "Epoch 27/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2496\n",
            "Epoch 28/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2373\n",
            "Epoch 29/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2263\n",
            "Epoch 30/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2162\n",
            "Epoch 31/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2070\n",
            "Epoch 32/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1984\n",
            "Epoch 33/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1906\n",
            "Epoch 34/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1834\n",
            "Epoch 35/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1767\n",
            "Epoch 36/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1704\n",
            "Epoch 37/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1646\n",
            "Epoch 38/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1591\n",
            "Epoch 39/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1540\n",
            "Epoch 40/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1492\n",
            "Epoch 41/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1447\n",
            "Epoch 42/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1404\n",
            "Epoch 43/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1364\n",
            "Epoch 44/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1325\n",
            "Epoch 45/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1290\n",
            "Epoch 46/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1256\n",
            "Epoch 47/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1223\n",
            "Epoch 48/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1192\n",
            "Epoch 49/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1163\n",
            "Epoch 50/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1134\n",
            "Epoch 1/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.2589\n",
            "Epoch 2/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.1273\n",
            "Epoch 3/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.0289\n",
            "Epoch 4/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.9411\n",
            "Epoch 5/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.8542\n",
            "Epoch 6/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.7633\n",
            "Epoch 7/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6663\n",
            "Epoch 8/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5625\n",
            "Epoch 9/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.4524\n",
            "Epoch 10/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3375\n",
            "Epoch 11/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2212\n",
            "Epoch 12/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.1065\n",
            "Epoch 13/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.9964\n",
            "Epoch 14/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.8946\n",
            "Epoch 15/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.8025\n",
            "Epoch 16/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.7206\n",
            "Epoch 17/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.6493\n",
            "Epoch 18/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.5873\n",
            "Epoch 19/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.5340\n",
            "Epoch 20/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4880\n",
            "Epoch 21/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4481\n",
            "Epoch 22/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.4136\n",
            "Epoch 23/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3834\n",
            "Epoch 24/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3569\n",
            "Epoch 25/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3336\n",
            "Epoch 26/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3130\n",
            "Epoch 27/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2947\n",
            "Epoch 28/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2784\n",
            "Epoch 29/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2636\n",
            "Epoch 30/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2504\n",
            "Epoch 31/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2383\n",
            "Epoch 32/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2274\n",
            "Epoch 33/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2175\n",
            "Epoch 34/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2083\n",
            "Epoch 35/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1998\n",
            "Epoch 36/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1920\n",
            "Epoch 37/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1849\n",
            "Epoch 38/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1782\n",
            "Epoch 39/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1719\n",
            "Epoch 40/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1661\n",
            "Epoch 41/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1608\n",
            "Epoch 42/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1557\n",
            "Epoch 43/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1509\n",
            "Epoch 44/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1463\n",
            "Epoch 45/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1422\n",
            "Epoch 46/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1381\n",
            "Epoch 47/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1343\n",
            "Epoch 48/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1307\n",
            "Epoch 49/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1274\n",
            "Epoch 50/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1241\n",
            "Epoch 1/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 2.2395\n",
            "Epoch 2/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 2.0828\n",
            "Epoch 3/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.9678\n",
            "Epoch 4/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.8640\n",
            "Epoch 5/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.7596\n",
            "Epoch 6/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.6497\n",
            "Epoch 7/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.5333\n",
            "Epoch 8/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4120\n",
            "Epoch 9/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2890\n",
            "Epoch 10/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.1681\n",
            "Epoch 11/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.0533\n",
            "Epoch 12/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.9475\n",
            "Epoch 13/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.8522\n",
            "Epoch 14/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.7678\n",
            "Epoch 15/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.6938\n",
            "Epoch 16/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.6295\n",
            "Epoch 17/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.5737\n",
            "Epoch 18/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.5253\n",
            "Epoch 19/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4833\n",
            "Epoch 20/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4466\n",
            "Epoch 21/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4144\n",
            "Epoch 22/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3863\n",
            "Epoch 23/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.3613\n",
            "Epoch 24/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3393\n",
            "Epoch 25/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3195\n",
            "Epoch 26/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3017\n",
            "Epoch 27/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2858\n",
            "Epoch 28/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2715\n",
            "Epoch 29/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2584\n",
            "Epoch 30/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2466\n",
            "Epoch 31/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2357\n",
            "Epoch 32/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2257\n",
            "Epoch 33/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2165\n",
            "Epoch 34/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2081\n",
            "Epoch 35/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2002\n",
            "Epoch 36/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1929\n",
            "Epoch 37/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1861\n",
            "Epoch 38/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1798\n",
            "Epoch 39/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1738\n",
            "Epoch 40/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1683\n",
            "Epoch 41/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1631\n",
            "Epoch 42/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1582\n",
            "Epoch 43/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1535\n",
            "Epoch 44/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1492\n",
            "Epoch 45/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1450\n",
            "Epoch 46/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1410\n",
            "Epoch 47/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1374\n",
            "Epoch 48/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1337\n",
            "Epoch 49/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1304\n",
            "Epoch 50/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1272\n",
            "Epoch 1/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 2.2816\n",
            "Epoch 2/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.1121\n",
            "Epoch 3/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.9956\n",
            "Epoch 4/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.8927\n",
            "Epoch 5/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.7894\n",
            "Epoch 6/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.6804\n",
            "Epoch 7/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.5641\n",
            "Epoch 8/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4418\n",
            "Epoch 9/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3157\n",
            "Epoch 10/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 1.1900\n",
            "Epoch 11/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.0691\n",
            "Epoch 12/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.9558\n",
            "Epoch 13/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.8528\n",
            "Epoch 14/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.7609\n",
            "Epoch 15/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.6802\n",
            "Epoch 16/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.6100\n",
            "Epoch 17/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.5494\n",
            "Epoch 18/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.4972\n",
            "Epoch 19/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.4523\n",
            "Epoch 20/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.4135\n",
            "Epoch 21/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.3800\n",
            "Epoch 22/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.3508\n",
            "Epoch 23/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.3255\n",
            "Epoch 24/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.3032\n",
            "Epoch 25/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2836\n",
            "Epoch 26/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2662\n",
            "Epoch 27/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2508\n",
            "Epoch 28/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2371\n",
            "Epoch 29/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2246\n",
            "Epoch 30/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.2134\n",
            "Epoch 31/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.2032\n",
            "Epoch 32/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1940\n",
            "Epoch 33/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1856\n",
            "Epoch 34/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1779\n",
            "Epoch 35/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1708\n",
            "Epoch 36/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1643\n",
            "Epoch 37/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1582\n",
            "Epoch 38/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1526\n",
            "Epoch 39/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1473\n",
            "Epoch 40/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1424\n",
            "Epoch 41/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1378\n",
            "Epoch 42/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1335\n",
            "Epoch 43/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1295\n",
            "Epoch 44/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1257\n",
            "Epoch 45/50\n",
            "45/45 [==============================] - 0s 1ms/step - loss: 0.1221\n",
            "Epoch 46/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1187\n",
            "Epoch 47/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1154\n",
            "Epoch 48/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1124\n",
            "Epoch 49/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1095\n",
            "Epoch 50/50\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 0.1068\n",
            "0.039780253791395846\n",
            "0.032832714329928826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je1TZV8S79ZM"
      },
      "source": [
        "Some things to notice in the example above:\n",
        "\n",
        "*   The function [zero_one_loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.zero_one_loss.html) was used to evaluate the models.\n",
        "*   10-fold cross-validation was used to evaluate both models. For this, the [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) class of Scikit-Learn was used.\n",
        "* A batch size of 32 was used. This way, in each training step, the network is provided a batch of 32 training examples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN60OrC3-E7u"
      },
      "source": [
        "# ANN trained on the MNIST dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu4IbIR7cWVm"
      },
      "source": [
        "The following example was taken from https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py. The [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MweZkvhB-VvW",
        "outputId": "0875a3f7-a3fb-4fdf-94b5-f29df3f8dee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "'''Trains a simple deep NN on the MNIST dataset.\n",
        "Gets to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_62 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.2458 - accuracy: 0.9233 - val_loss: 0.0988 - val_accuracy: 0.9697\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.1016 - accuracy: 0.9689 - val_loss: 0.0740 - val_accuracy: 0.9764\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0740 - accuracy: 0.9777 - val_loss: 0.0811 - val_accuracy: 0.9766\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0597 - accuracy: 0.9815 - val_loss: 0.0851 - val_accuracy: 0.9763\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0496 - accuracy: 0.9849 - val_loss: 0.0811 - val_accuracy: 0.9790\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.0780 - val_accuracy: 0.9807\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 0.0732 - val_accuracy: 0.9818\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0336 - accuracy: 0.9904 - val_loss: 0.0858 - val_accuracy: 0.9802\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0313 - accuracy: 0.9908 - val_loss: 0.0862 - val_accuracy: 0.9841\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.0898 - val_accuracy: 0.9813\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 10s 20ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 0.0892 - val_accuracy: 0.9824\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 0.1055 - val_accuracy: 0.9817\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 10s 20ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.1025 - val_accuracy: 0.9834\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.1011 - val_accuracy: 0.9832\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0211 - accuracy: 0.9940 - val_loss: 0.0983 - val_accuracy: 0.9844\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 0.1125 - val_accuracy: 0.9831\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.1250 - val_accuracy: 0.9830\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0186 - accuracy: 0.9948 - val_loss: 0.1275 - val_accuracy: 0.9840\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 9s 20ms/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.1088 - val_accuracy: 0.9830\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 10s 20ms/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 0.1249 - val_accuracy: 0.9835\n",
            "Test loss: 0.12487834692001343\n",
            "Test accuracy: 0.9835000038146973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0G8yt1rB-K6",
        "outputId": "a8496646-e8c0-403f-cbe0-9e26a1066459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "#plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "#plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xddZ3v/9e7uTRpmza9tzSlLVBKq0KRUkBQQHCGi4KAo6Co6IyMoxx1ZpgRdAY9PYeDHtHfjIqj6HQEL6BTQZGpIpcWdAClQim3thR+YNJraJJeSNLcPuePtRJ20912l3ZnJ3u/n49HHlmX79rrs3d29mev720pIjAzM+tvWKEDMDOzwckJwszMsnKCMDOzrJwgzMwsKycIMzPLygnCzMyycoIwAyR9X9L/zrHsS5LOzndMZoXmBGFmZlk5QZgVEUnlhY7BiocThA0ZadXOP0haJelVSf8uabKkX0naIek+SWMzyl8g6RlJLZKWS5qbse94SY+nx/0EqOp3rndKWpke+7CkY3OM8XxJT0jaLqle0hf77T8tfbyWdP8V6fZqSV+V9LKkbZJ+l247Q1JDltfh7HT5i5KWSPqhpO3AFZIWSnokPcdGSd+UVJlx/Bsk3SupSdJmSZ+TNEVSq6TxGeXeLKlRUkUuz92KjxOEDTWXAO8AjgbeBfwK+BwwkeT9/CkASUcDtwGfSfctBX4pqTL9sPw58ANgHPCf6eOSHns8sBj4a2A88B3gLknDc4jvVeBDQC1wPvA3kt6dPu6MNN5vpDHNB1amx90InAC8JY3pH4GeHF+TC4El6Tl/BHQDfwtMAE4BzgI+kcZQA9wH/Bo4DDgKuD8iNgHLgfdmPO4HgdsjojPHOKzIOEHYUPONiNgcEeuB3wK/j4gnIqIduBM4Pi33PuC/IuLe9APuRqCa5AP4ZKAC+JeI6IyIJcBjGee4EvhORPw+Iroj4hZgV3rcPkXE8oh4KiJ6ImIVSZI6Pd39fuC+iLgtPe/WiFgpaRjwUeDTEbE+PefDEbErx9fkkYj4eXrOtoj4Y0Q8GhFdEfESSYLrjeGdwKaI+GpEtEfEjoj4fbrvFuByAEllwGUkSdRKlBOEDTWbM5bbsqyPSpcPA17u3RERPUA9MC3dtz52n6ny5YzlGcDfp1U0LZJagOnpcfsk6SRJy9KqmW3Ax0m+yZM+xgtZDptAUsWVbV8u6vvFcLSkuyVtSqud/k8OMQD8ApgnaRbJVdq2iPjD64zJioAThBWrDSQf9ABIEsmH43pgIzAt3dbr8IzleuD6iKjN+BkREbflcN4fA3cB0yNiDPBtoPc89cCRWY55BWjfy75XgREZz6OMpHoqU/8pmf8NWA3MjojRJFVwmTEckS3w9CrspyRXER/EVw8lzwnCitVPgfMlnZU2sv49STXRw8AjQBfwKUkVki4GFmYc+13g4+nVgCSNTBufa3I4bw3QFBHtkhaSVCv1+hFwtqT3SiqXNF7S/PTqZjHwNUmHSSqTdEra5rEWqErPXwH8E7C/tpAaYDuwU9IxwN9k7LsbmCrpM5KGS6qRdFLG/luBK4ALcIIoeU4QVpQiYg3JN+FvkHxDfxfwrojoiIgO4GKSD8ImkvaKOzKOXQF8DPgm0AysS8vm4hPAIkk7gOtIElXv4/4JOI8kWTWRNFAfl+6+GniKpC2kCfgyMCwitqWP+T2Sq59Xgd16NWVxNUli2kGS7H6SEcMOkuqjdwGbgOeBMzP2/zdJ4/jjEZFZ7WYlSL5hkJllkvQA8OOI+F6hY7HCcoIwsz6STgTuJWlD2VHoeKywXMVkZgBIuoVkjMRnnBwMfAVhZmZ74SsIMzPLqmgm9powYULMnDmz0GGYmQ0pf/zjH1+JiP5ja4AiShAzZ85kxYoVhQ7DzGxIkbTX7syuYjIzs6ycIMzMLCsnCDMzy6po2iCy6ezspKGhgfb29kKHkndVVVXU1dVRUeF7u5jZoVHUCaKhoYGamhpmzpzJ7hN3FpeIYOvWrTQ0NDBr1qxCh2NmRaKoq5ja29sZP358UScHAEmMHz++JK6UzGzgFHWCAIo+OfQqledpZgOnqKuYzMwGi67uHnbu6mJ7Wxfb2zvZ1tbJ9rZOtrd30t7ZQ0QQQE8k1cYREES6Dj3ptEg9Pb3l0jIRTBlTzftPOnyf5389nCDyrKWlhR//+Md84hOfOKDjzjvvPH784x9TW1ubp8jMbF8igl1dPbR3dtPW2U1rRzdtHd19620dr/3euauL7e1dyQd++qHfmwiS9S527urKW6zHH17rBDEUtbS08K1vfWuPBNHV1UV5+d5f/qVLl+Y7NLMhq7sn2Nn+2jfx1vSDu72zu+9Dvb2rh139t3X225du39WbANLyvR/+PQc4l2lNVTmjqyoYXV3BmOpyDh83gtHVFem21/aNripnTHW6XF3B8PJhDJMYJhBCw5J7xA6TkJLf9FsXIOW3etkJIs+uueYaXnjhBebPn09FRQVVVVWMHTuW1atXs3btWt797ndTX19Pe3s7n/70p7nyyiuB16YO2blzJ+eeey6nnXYaDz/8MNOmTeMXv/gF1dXVBX5mZgcnItje1sWm7e00vdqx27ftvX0L7/2GvuMAv41LUFVeRlXFMKoqyhhenv6uKKOqfBi1Iyo5rLaM6ooyqiqT3yMqy6iqSJarK/dcz/w9srKcUVXllA0rrrbAkkkQ//OXz/Dshu2H9DHnHTaaL7zrDfss86UvfYmnn36alStXsnz5cs4//3yefvrpvu6oixcvZty4cbS1tXHiiSdyySWXMH78+N0e4/nnn+e2227ju9/9Lu9973v52c9+xuWXX35In4vZodTW0c2m7e1s3u1n1x7Lu7p69voYNcPLGV1dQU36bbtubDWjp47e45v46OoKRg0v7/vQr6oYxvDyMoanyaCqvIyKMrkjx+tQMglisFi4cOFuYxW+/vWvc+eddwJQX1/P888/v0eCmDVrFvPnzwfghBNO4KWXXhqweK247NzVxdrNO1iz6bWftZt38GpHF5Vlw6gsH0Zl2TAqen/3bkvXK8uHUVEmKsvL0nVRWTaMHbu62LJ9V19S2NG+5zf8qophTBldxeTRVcyfXsvk0cOZnK6PH1mZVssk1THF+G18KCqZBLG/b/oDZeTIkX3Ly5cv57777uORRx5hxIgRnHHGGVnHMgwfPrxvuaysjLa2tgGJ1Yaujq4eXnxl526JYM3mHTQ0v/beGVFZxuzJNZw1dxK1Iyrp6OphV1cPnd09dGT87kh/v9rRRUtb777oK9/R1c2o4eVMGl3FkRNHcuqR45k0uqovGUwePZzJY6qoGV7ub/FDTMkkiEKpqalhx47sd2/ctm0bY8eOZcSIEaxevZpHH310gKOzwaCto5sduzoh0i6OfV0be7sxpl0a2b1rY+96Tw+sb2lj7eYdrN60g7WbdvBC40660hbW8mHiiIkjOf7wsVx64nTmTBnNnMk11I2tZpi/pds+OEHk2fjx4zn11FN54xvfSHV1NZMnT+7bd8455/Dtb3+buXPnMmfOHE4++eQCRmr51tMT1De38tzGHazetJ3V6e+Xm1o5VHf+nVZbzTFTkquCOVNqmDOlhiMmjKKyvOjHxFoeFM09qRcsWBD9bxj03HPPMXfu3AJFNPBK7fkOZtvbO1mzaQerN27n2TQRrNm0g9aObiDpVTNr/EiOmVrDnMmjGTeqsq+L4zC91n2xf1fHbNsFTBpdxdGTR1FT5cka7cBI+mNELMi2z1cQZgdhe3snG1raWLdlZ98VwXMbd7C+5bW6/jHVFRwzpYb3LpjOMVNqmDt1NLMnj2JEpf/9bHDzO9RsL9o7u9m4rZ2NLW1s6PvdxoaWdjamvzNHx5YNE0dOHMkJM8bygZMPZ+6U0RwztYYpo6vcOGtDUl4ThKRzgH8FyoDvRcSX+u2fASwGJgJNwOUR0ZDu+zJwflr0f0XET15PDBFREv+cxVJVmG9d3T1sb++ipbWDbW2dtLR1sq21k83b29m4rZ0NaRLY2NLO1lc79jh+/MhKDqutZub4kbzlyAkcVlvF1DHVHDFxJEdNGsXw8rICPCuz/MhbgpBUBtwEvANoAB6TdFdEPJtR7Ebg1oi4RdLbgRuAD0o6H3gzMB8YDiyX9KuIOKCRblVVVWzdurXop/zuvR9EVVVVoUMZcN09wdPrt7Ghpa3vA7+lNZl+YVtbmgR611v3PQJ31PDyvg/8N00bw2FjqplaW81hY6o4rLaaKWOqqKpwArDSkc8riIXAuoh4EUDS7cCFQGaCmAf8Xbq8DPh5xvaHIqIL6JK0CjgH+OmBBFBXV0dDQwONjY2v/1kMEb13lCsFW3fu4qHnG1m+ppGH1jbS3Nq52/6KMjEmHXRVO6KSyaOrmDO5htHVFdSO6N1ekZapZEx1BZNGD2e0G3jNdpPPBDENqM9YbwBO6lfmSeBikmqoi4AaSePT7V+Q9FVgBHAmuyeWnFRUVPgOa0Wguyd4sqGF5WsaeXDNFlat30ZEUt1z5pxJnD5nIrMn1fR96I+oLCvqK0azgVLoRuqrgW9KugJ4CFgPdEfEbySdCDwMNAKPAN39D5Z0JXAlwOGHH/qpbq1wsl0lSDB/ei1/e/bRnDFnIm88bIwHepnlUT4TxHpgesZ6XbqtT0RsILmCQNIo4JKIaEn3XQ9cn+77MbC2/wki4mbgZkjGQRz6p2ADpbsnWJVeJSxf28iqhpY9rhLeNnsiY0dWFjpUs5KRzwTxGDBb0iySxHAp8P7MApImAE0R0QNcS9KjqbeBuzYitko6FjgW+E0eY7UCaGnt4MG1jSxbvYUH+10lfOas5CrhTdN8lWBWKHlLEBHRJekq4B6Sbq6LI+IZSYuAFRFxF3AGcIOkIKli+mR6eAXw27QeeTtJ99f83Y7JBkREsHbzTh5YvYVlq7ew4uUmegLGjazkjDmTOMNXCWaDSlFPtWGF197ZzSMvbOWB1Vt4YPWWvhHG86aO5qy5kzjzmEkcV1frqZ3NCsRTbdiA2tDS1neV8N8vvEJ7Zw/VFWWcetQErnr7UZw5ZxJTxpTemA2zocYJwg5ad0+wsr6ZB1Zv4f7ntrB6UzK9+fRx1bxvwXTePncyJ80a50FmZkOME4S9LhHBU+u3ccfj67l71QZe2dlB2TCxYMZYrj33GM6aO4kjJ47yeASzIcwJwg5IQ3Mrv1i5gTseb+CFxlepLB/G2XMnce4bp/K2oycyptqjkc2KhROE7df29k5+9dRG7nh8Pb///5sAWDhzHH/11iM4701TnRTMipQThGXV2d3DQ2sbueOJ9dz37GZ2dfVwxISR/P07jubdx09j+rgRhQ7RzPLMCcL6RASrGrZx5xPr+eWTG9j6agfjRlZy6YnTuejNdRxXN8ZtCmYlxAnCWN/Sxp2PN3DHE+t5MW1XeMfcyVx0/DROnzORijLfz9isFDlBlLAd7Z18/f7n+Y//fomunuCkWeP467cdwTlvdLuCmTlBlKSenuDOJ9bzpV+v5pWdu3jfgul88syj3K5gZrtxgigxTzVs4wt3Pc3jf2ph/vRavvehBRw3vbbQYZnZIOQEUSK27tzFjb9Zw+2P1TN+5HBu/IvjuPj4aZ4p1cz2ygmiyHV19/DDR1/ma/eupbWjm788dRafOnu2b69pZvvlBFHEHnlhK//zl8+wetMOTjtqAl+8YB5HTaopdFhmNkQ4QRShDS1tXL/0Of5r1Uam1Vbz7ctP4M/fMNljGMzsgDhBFJH2zm6+99sXuWnZC/RE8JmzZ/Px04/0LKpm9ro4QRSBiOD+57aw6O5n+VNTK+e+cQqfO2+uu62a2UFxghji6ptaue4XT7NsTSNHTRrFD//yJE6bPaHQYZlZEXCCGKK6e4JbHn6JG3+zBgH/dP5cPvyWmZ4Ww8wOmbwmCEnnAP8KlAHfi4gv9ds/A1gMTASagMsjoiHd93+B84FhwL3Ap6NYbqB9kNZs2sFnf7aKlfUtnDlnIv/7ojcxrba60GGZWZHJW4KQVAbcBLwDaAAek3RXRDybUexG4NaIuEXS24EbgA9KegtwKnBsWu53wOnA8nzFOxTs6urmpmUv8G/L11FTVcG/XjqfC447zL2TzCwv8nkFsRBYFxEvAki6HbgQyEwQ84C/S5eXAT9PlwOoAioBARXA5jzGOuj98eUmPvuzp1i3ZScXHT+Nf37nPMaNrCx0WGZWxPKZIKYB9RnrDcBJ/co8CVxMUg11EVAjaXxEPCJpGbCRJEF8MyKe638CSVcCVwIcfvjhh/4ZDAI7d3XxlV+v5tZHX+awMdX8x0dO5Mw5kwodlpmVgEI3Ul8NfFPSFcBDwHqgW9JRwFygLi13r6S3RsRvMw+OiJuBmwEWLFhQdO0Ty1Zv4fN3PsXG7e18+JSZXP3ncxg1vNB/MjMrFfn8tFkPTM9Yr0u39YmIDSRXEEgaBVwSES2SPgY8GhE7032/Ak4BdksQxWrrzl0suvtZfrFyA7MnjWLJx9/CCTPGFjosMysx+ewT+RgwW9IsSZXApcBdmQUkTZDUG8O1JD2aAP4EnC6pXFIFSQP1HlVMxSYiuPOJBs7+2oMsfWojnzl7Nnd/6jQnBzMriLxdQUREl6SrgHtIurkujohnJC0CVkTEXcAZwA2SgqSK6ZPp4UuAtwNPkTRY/zoifpmvWAeDhuZWPn/n0zy4tpHjD6/ly5ccy9GTPbGemRWOimVowYIFC2LFihWFDuN1+cGjL3PD0uQC6R//fA4fPGUmZb5Pg5kNAEl/jIgF2fa5xbPA7n12M//886d56+wJ3HDxm6gb6/mTzGxwcIIooG2tnXz+zqc4ZkoN//7hE6ks9zQZZjZ4OEEU0KK7n2Xrqx0svsLJwcwGH38qFciyNVv42eMN/M3pR/LGaWMKHY6Z2R6cIApge3snn7vjKY6ePIr/cdZRhQ7HzCwrJ4gCuGHpc2ze3s5X3nMcw8t9tzczG5ycIAbY755/hdv+UM/H3nYEx02vLXQ4ZmZ75QQxgHbu6uKzP1vFERNH8rdnH13ocMzM9sm9mAbQl3+1mg3b2ljy8VOoqnDVkpkNbr6CGCCPvLCVHzz6Mh89dRYnzBhX6HDMzPbLCWIAtHYkVUszxo/g6j+bU+hwzMxy4iqmAfCVe9bwp6ZWbr/yZKorXbVkZkODryDybMVLTXz/4Zf40CkzOPmI8YUOx8wsZ04QedTe2c0/LlnFtNpqPnvOMYUOx8zsgLiKKY++du9aXnzlVX70Vycx0rcKNbMhxlcQefLEn5r53m9f5LKFh3PqURMKHY6Z2QFzgsiD9s5u/mHJKqaMruJz57lqycyGJtd75MHX73+edVt2cstHF1JTVVHocMzMXpe8XkFIOkfSGknrJF2TZf8MSfdLWiVpuaS6dPuZklZm/LRLenc+Yz1UnmrYxnceepG/OKGO04+eWOhwzMxet7wlCEllwE3AucA84DJJ8/oVuxG4NSKOBRYBNwBExLKImB8R84G3A63Ab/IV66HS0dXDPyx5kgmjKvmnd/Z/qmZmQ0s+ryAWAusi4sWI6ABuBy7sV2Ye8EC6vCzLfoD3AL+KiNa8RXqIfHPZOlZv2sH/uehNjKl21ZKZDW35TBDTgPqM9YZ0W6YngYvT5YuAGkn9R5NdCtyW7QSSrpS0QtKKxsbGQxDy6/fMhm18a9k6Ljp+GmfNnVzQWMzMDoVC92K6Gjhd0hPA6cB6oLt3p6SpwJuAe7IdHBE3R8SCiFgwcWLh6vs7u3v4h/9cRe2ISr7wLlctmVlxyGcvpvXA9Iz1unRbn4jYQHoFIWkUcElEtGQUeS9wZ0R05jHOg/bt5S/w7MbtfPvyE6gdUVnocMzMDol8XkE8BsyWNEtSJUlV0V2ZBSRNkNQbw7XA4n6PcRl7qV4aLF7d1cU3HljH+cdO5Zw3Til0OGZmh0zeEkREdAFXkVQPPQf8NCKekbRI0gVpsTOANZLWApOB63uPlzST5ArkwXzFeCi8vLWVju4ezn/T1EKHYmZ2SOV1oFxELAWW9tt2XcbyEmDJXo59iT0btQed+uakc1Xd2OoCR2JmdmgVupF6yKtvShLE9LEjChyJmdmh5QRxkBqa2xg1vJzaER73YGbFxQniIDU0t1I3thpJhQ7FzOyQcoI4SPVNbdS5esnMilBOCULSHZLOz+iSakBEUN/cyvRxbqA2s+KT6wf+t4D3A89L+pKkOXmMachobu2ktaPbDdRmVpRyShARcV9EfAB4M/AScJ+khyV9RFLJts729mByF1czK0Y5Vxmlk+hdAfwV8ATwryQJ4968RDYE9I6BmD7OVxBmVnxyGign6U5gDvAD4F0RsTHd9RNJK/IV3GBX39QGOEGYWXHKdST11yNiWbYdEbHgEMYzpDQ0tzJ2RAWjhvvOrWZWfHKtYponqbZ3RdJYSZ/IU0xDRn2zu7iaWfHKNUF8LHMa7ohoBj6Wn5CGjoYmd3E1s+KVa4IoU8ZQ4fR+0yV944OenqChpc1dXM2saOVaef5rkgbp76Trf51uK1mNO3fR0dVDnRuozaxI5ZogPkuSFP4mXb8X+F5eIhoiPAbCzIpdTgkiInqAf0t/jIwxEK5iMrMiles4iNnADcA8oKp3e0Qckae4Br2GdAyEryDMrFjl2kj9HyRXD13AmcCtwA/zFdRQUN/cysSa4VRVlBU6FDOzvMg1QVRHxP2AIuLliPgicH7+whr86pvamO6rBzMrYrkmiF3pVN/PS7pK0kXAqP0dJOkcSWskrZN0TZb9MyTdL2mVpOWS6jL2HS7pN5Kek/SspJk5xjogkmm+3f5gZsUr1wTxaWAE8CngBOBy4MP7OiAdK3ETcC5J28Vlkub1K3YjcGtEHAssImnn6HUr8JWImAssBLbkGGvedXX3sHFbuxuozayo7TdBpB/074uInRHREBEfiYhLIuLR/Ry6EFgXES9GRAdwO3BhvzLzgAfS5WW9+9NEUh4R9wKk527N/Wnl18Zt7XT3hBuozayo7TdBREQ3cNrreOxpQH3GekO6LdOTwMXp8kVATTqt+NFAS3onuyckfSVNVLuRdKWkFZJWNDY2vo4QXx9P821mpSDXKqYnJN0l6YOSLu79OQTnvxo4XdITwOnAeqCbpPvtW9P9JwJHkNyLYjcRcXNELIiIBRMnTjwE4eSmt4urq5jMrJjlOpK6CtgKvD1jWwB37OOY9cD0jPW6dNtrDxCxgfQKQtIo4JKIaJHUAKyMiBfTfT8HTgb+Pcd486qhuZVhgqm1VfsvbGY2ROU6kvojr+OxHwNmS5pFkhguJbmvdR9JE4CmdKT2tcDijGNrJU2MiEaSxDRobkxU39zG1DHVVJTlfEM+M7MhJ9eR1P9BcsWwm4j46N6OiYguSVcB9wBlwOKIeEbSImBFRNwFnAHcICmAh4BPpsd2S7oauD+dRfaPwHcP6JnlUX1Tqxuozazo5VrFdHfGchVJg/KG/R0UEUuBpf22XZexvARYspdj7wWOzTG+AdXQ3MZpsycUOgwzs7zKtYrpZ5nrkm4DfpeXiAa5XV3dbN7R7isIMyt6r7cSfTYw6VAGMlSsb24jwj2YzKz45doGsYPd2yA2kdwjouTUN6ddXD0GwsyKXK5VTDX5DmSoaOgbJOcqJjMrbjlVMUm6SNKYjPVaSe/OX1iDV31TGxVlYlKNx0CYWXHLtQ3iCxGxrXclIlqAL+QnpMGtvrmVabXVlA1ToUMxM8urXBNEtnK5dpEtKg1NnubbzEpDrglihaSvSToy/fkayeC1ktPQ3EadezCZWQnINUH8D6AD+AnJtN3tpKOeS8mru7rY+mqHx0CYWUnItRfTq8Aed4QrNQ3u4mpmJSTXXkz3SqrNWB8r6Z78hTU49XVx9RWEmZWAXKuYJqQ9lwCIiGZKcCR1fZNvFGRmpSPXBNEj6fDeFUkzyTK7a7Grb26juqKM8SMrCx2KmVne5dpV9fPA7yQ9CIjkbm9X5i2qQap3mu9kBnIzs+KWayP1ryUtIEkKTwA/B9ryGdhg1NDc5uolMysZuU7W91fAp0luG7qS5Pafj7D7LUiLXn1zKwtmji10GGZmAyLXNohPAycCL0fEmcDxQMu+Dyku21o72dHe5Wm+zaxk5Jog2iOiHUDS8IhYDczJX1iDT71ncTWzEpNrgmhIx0H8HLhX0i+Al/d3kKRzJK2RtE7SHgPtJM2QdL+kVZKWS6rL2NctaWX6c1euTyhfesdAeJoNMysVuTZSX5QuflHSMmAM8Ot9HSOpDLgJeAfQADwm6a6IeDaj2I3ArRFxi6S3AzcAH0z3tUXE/NyfSn7VN6WjqJ0gzKxEHPCMrBHxYI5FFwLrIuJFAEm3AxcCmQliHvB36fIykiuUQam+uZWaqnLGjKgodChmZgPi9d6TOhfTgPqM9YZ0W6YngYvT5YuAGknj0/UqSSskPbq3mxNJujIts6KxsfFQxr6H+qZWXz2YWUnJZ4LIxdXA6ZKeAE4H1gPd6b4ZEbEAeD/wL5KO7H9wRNwcEQsiYsHEiRPzGmgyBsIN1GZWOvKZINYD0zPW69JtfSJiQ0RcHBHHk4zW7r1bHRGxPv39IrCcpGttQUSE7wNhZiUnnwniMWC2pFmSKoFLgd16I0maIKk3hmuBxen2sZKG95YBTmX3tosB9crODto6uz2Lq5mVlLwliIjoAq4C7gGeA34aEc9IWiTpgrTYGcAaSWuBycD16fa5JHexe5Kk8fpL/Xo/Dai+ab49zYaZlZC83lc6IpYCS/ttuy5jeQmwJMtxDwNvymdsB6I+vVGQq5jMrJQUupF6SOi9D4RvNWpmpcQJIgcNza2MH1nJyOF5veAyMxtUnCBy0NDcRp3bH8ysxDhB5KD3RkFmZqXECWI/unuC9S1tHkVtZiXHCWI/Nm9vp7M7PIrazEqOE8R+NDR7FlczK01OEPvhLq5mVqqcIPajvrkVCaY5QZhZiXGC2I/6pjYm11QxvLys0KGYmQ0oJ4j9aGh2F1czK01OEPuR3AfCDdRmVnqcIPahs7uHjdvaPM23mZUkJ4h92NjSTk/gaTbMrCQ5QexDfbO7uJpZ6XKC2IfeMRAeJGdmpcgJYh/qm1spGyamjqkqdO9X9cIAAA1tSURBVChmZgPOCWIfGprbOKy2ivIyv0xmVnr8ybcP9U2t1NW6esnMSlNeE4SkcyStkbRO0jVZ9s+QdL+kVZKWS6rrt3+0pAZJ38xnnHtT39zmWVzNrGTlLUFIKgNuAs4F5gGXSZrXr9iNwK0RcSywCLih3/7/BTyUrxj3pb2zm8Ydu9xAbWYlK59XEAuBdRHxYkR0ALcDF/YrMw94IF1elrlf0gnAZOA3eYxxr/qm+fYYCDMrUflMENOA+oz1hnRbpieBi9Pli4AaSeMlDQO+Cly9rxNIulLSCkkrGhsbD1HYCY+BMLNSV+hG6quB0yU9AZwOrAe6gU8ASyOiYV8HR8TNEbEgIhZMnDjxkAbW0DsGwlcQZlaiyvP42OuB6Rnrdem2PhGxgfQKQtIo4JKIaJF0CvBWSZ8ARgGVknZGxB4N3fnS0NxGZfkwJo4aPlCnNDMbVPKZIB4DZkuaRZIYLgXen1lA0gSgKSJ6gGuBxQAR8YGMMlcACwYyOUBSxVRXW82wYRrI05qZDRp5q2KKiC7gKuAe4DngpxHxjKRFki5Ii50BrJG0lqRB+vp8xXOg6pvaPEmfmZW0fF5BEBFLgaX9tl2XsbwEWLKfx/g+8P08hLdP9c2tHFs3ZqBPa2Y2aBS6kXpQ2tHeSUtrpxuozaykOUFk0TsGwl1czayUOUFk4Wm+zcycILKq9yhqMzMniGwamlsZWVnG2BEVhQ7FzKxgnCCyqG9qo27sCCSPgTCz0uUEkUVDc6un+TazkucE0U9EJDcKcgO1mZU4J4h+Wlo7ebWj211czazkOUH00zvNt3swmVmpc4Lop74p7eLqKiYzK3FOEP009N4oyI3UZlbinCD6qW9uZUx1BaOrPAbCzEqbE0Q/9U1t7uJqZoYTxB7qm1vd/mBmhhPEbiKC9c1t7sFkZoYTxG4ad+xiV1ePx0CYmeEEsZu+MRCuYjIzy2+CkHSOpDWS1km6Jsv+GZLul7RK0nJJdRnbH5e0UtIzkj6ezzh79Y2BcCO1mVn+EoSkMuAm4FxgHnCZpHn9it0I3BoRxwKLgBvS7RuBUyJiPnAScI2kw/IVa6/eMRDTan0FYWaWzyuIhcC6iHgxIjqA24EL+5WZBzyQLi/r3R8RHRGxK90+PM9x9qlvamPCqOFUV5YNxOnMzAa1fH7wTgPqM9Yb0m2ZngQuTpcvAmokjQeQNF3SqvQxvhwRG/qfQNKVklZIWtHY2HjQAdd7mm8zsz6FbqS+Gjhd0hPA6cB6oBsgIurTqqejgA9Lmtz/4Ii4OSIWRMSCiRMnHnQwHgNhZvaafCaI9cD0jPW6dFufiNgQERdHxPHA59NtLf3LAE8Db81jrHR197Cxpd1dXM3MUvlMEI8BsyXNklQJXArclVlA0gRJvTFcCyxOt9dJqk6XxwKnAWvyGCubtrfT1RMeJGdmlspbgoiILuAq4B7gOeCnEfGMpEWSLkiLnQGskbQWmAxcn26fC/xe0pPAg8CNEfFUvmIFT/NtZtZfeT4fPCKWAkv7bbsuY3kJsCTLcfcCx+Yztv4a+m4U5ComMzMofCP1oFHf3IYEU8c4QZiZgRNEn4amVqaOrqKy3C+JmRk4QfSpb26lzg3UZmZ9nCBSDc1tbqA2M8vgBAHs6upm03aPgTAzy+QEAWxoaScCj4EwM8vgBAHUN/XeB8JXEGZmvZwgSNofADdSm5llcIIg6cFUUSamjK4qdChmZoOGEwRJFdNhtdWUDVOhQzEzGzScIHAXVzOzbJwgSOZhchdXM7PdlXyCaO3o4pWdHe7iambWT8kniLaObi447jCOrRtT6FDMzAaVvE73PRSMHzWcr192fKHDMDMbdEr+CsLMzLJzgjAzs6ycIMzMLCsnCDMzyyqvCULSOZLWSFon6Zos+2dIul/SKknLJdWl2+dLekTSM+m+9+UzTjMz21PeEoSkMuAm4FxgHnCZpHn9it0I3BoRxwKLgBvS7a3AhyLiDcA5wL9Iqs1XrGZmtqd8XkEsBNZFxIsR0QHcDlzYr8w84IF0eVnv/ohYGxHPp8sbgC3AxDzGamZm/eQzQUwD6jPWG9JtmZ4ELk6XLwJqJI3PLCBpIVAJvND/BJKulLRC0orGxsZDFriZmRV+oNzVwDclXQE8BKwHunt3SpoK/AD4cET09D84Im4Gbk7LNkp6+SBimQC8chDH55vjOziO7+A4voMzmOObsbcd+UwQ64HpGet16bY+afXRxQCSRgGXRERLuj4a+C/g8xHx6P5OFhEHVQUlaUVELDiYx8gnx3dwHN/BcXwHZ7DHtzf5rGJ6DJgtaZakSuBS4K7MApImSOqN4Vpgcbq9EriTpAF7SR5jNDOzvchbgoiILuAq4B7gOeCnEfGMpEWSLkiLnQGskbQWmAxcn25/L/A24ApJK9Of+fmK1czM9pTXNoiIWAos7bftuozlJcAeVwgR8UPgh/mMLYubB/h8B8rxHRzHd3Ac38EZ7PFlpYgodAxmZjYIeaoNMzPLygnCzMyyKqkEkcPcUMMl/STd/3tJMwcwtumSlkl6Np2D6tNZypwhaVtGw/112R4rz3G+JOmp9PwrsuyXpK+nr+EqSW8ewNjmZLw2KyVtl/SZfmUG9DWUtFjSFklPZ2wbJ+leSc+nv8fu5dgPp2Wel/ThAYzvK5JWp3+/O/c2zc3+3gt5jO+LktZn/A3P28ux+/x/z2N8P8mI7SVJK/dybN5fv4MWESXxA5SRjMY+gmRk9pPAvH5lPgF8O12+FPjJAMY3FXhzulwDrM0S3xnA3QV+HV8CJuxj/3nArwABJwO/L+DfexMwo5CvIUlvvDcDT2ds+7/ANenyNcCXsxw3Dngx/T02XR47QPH9GVCeLn85W3y5vBfyGN8Xgatz+Pvv8/89X/H12/9V4LpCvX4H+1NKVxC5zA11IXBLurwEOEuSBiK4iNgYEY+nyztIugb3n5pkKLiQZPxKRDLAsTYdET/QzgJeiIiDGV1/0CLiIaCp3+bM99ktwLuzHPrnwL0R0RQRzcC9JBNX5j2+iPhNJN3UAR4lGeRaEHt5/XKRy//7QdtXfOlnx3uB2w71eQdKKSWIXOaG6iuT/oNsA8YzwNKqreOB32fZfYqkJyX9StIbBjSwRAC/kfRHSVdm2Z/L6zwQLmXv/5iFfg0nR8TGdHkTyRig/gbL6/hRkivCbPb3Xsinq9IqsMV7qaIbDK/fW4HNkU48mkUhX7+clFKCGBKUTDnyM+AzEbG93+7HSapMjgO+Afx8oOMDTouIN5NM4/5JSW8rQAz7lI7EvwD4zyy7B8Nr2CeSuoZB2ddc0ueBLuBHeylSqPfCvwFHAvOBjSTVOIPRZez76mHQ/y+VUoLY79xQmWUklQNjgK0DEl1yzgqS5PCjiLij//6I2B4RO9PlpUCFpAkDFV963vXp7y0k06Es7Fckl9c5384FHo+Izf13DIbXENjcW+2W/t6SpUxBX0clE2i+E/hAmsT2kMN7IS8iYnNEdEcyged393LeQr9+5STzzP1kb2UK9fodiFJKEPudGypd7+0t8h7ggb39cxxqaX3lvwPPRcTX9lJmSm+biJJp0IcxsAlspKSa3mWSxsyn+xW7C/hQ2pvpZGBbRnXKQNnrN7dCv4apzPfZh4FfZClzD/BnksamVSh/lm7LO0nnAP8IXBARrXspk8t7IV/xZbZpXbSX8+by/55PZwOrI6Ih285Cvn4HpNCt5AP5Q9LDZi1J74bPp9sWkfwjAFSRVEusA/4AHDGAsZ1GUtWwCliZ/pwHfBz4eFrmKuAZkh4ZjwJvGeDX74j03E+mcfS+hpkxiuROgi8ATwELBjjGkSQf+GMythXsNSRJVBuBTpJ68L8kade6H3geuA8Yl5ZdAHwv49iPpu/FdcBHBjC+dST1973vw96efYcBS/f1Xhig+H6QvrdWkXzoT+0fX7q+x//7QMSXbv9+73suo+yAv34H++OpNszMLKtSqmIyM7MD4ARhZmZZOUGYmVlWThBmZpaVE4SZmWXlBGE2CKSzzN5d6DjMMjlBmJlZVk4QZgdA0uWS/pDO4f8dSWWSdkr6/5Tcx+N+SRPTsvMlPZpxX4Wx6fajJN2XThj4uKQj04cfJWlJei+GHw3UTMJme+MEYZYjSXOB9wGnRsR8oBv4AMno7RUR8QbgQeAL6SG3Ap+NiGNJRv72bv8RcFMkEwa+hWQkLiQz+H4GmEcy0vbUvD8ps30oL3QAZkPIWcAJwGPpl/tqkon2enhtUrYfAndIGgPURsSD6fZbgP9M59+ZFhF3AkREO0D6eH+IdO6e9C5kM4Hf5f9pmWXnBGGWOwG3RMS1u22U/rlfudc7f82ujOVu/P9pBeYqJrPc3Q+8R9Ik6Lu39AyS/6P3pGXeD/wuIrYBzZLemm7/IPBgJHcLbJD07vQxhksaMaDPwixH/oZilqOIeFbSP5HcBWwYyQyenwReBRam+7aQtFNAMpX3t9ME8CLwkXT7B4HvSFqUPsZfDODTMMuZZ3M1O0iSdkbEqELHYXaouYrJzMyy8hWEmZll5SsIMzPLygnCzMyycoIwM7OsnCDMzCwrJwgzM8vq/wFmC0o6LE/7TwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skb5Mr-H9uxG"
      },
      "source": [
        "# Miscelaneous examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLdsTpt-x1tZ",
        "outputId": "4b7581e1-944d-4b3c-b30b-fe6ee7b85820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "a = np.arange(6).reshape(2,3) + 10\n",
        "\n",
        "print(a)\n",
        "\n",
        "print(np.argmax(a))\n",
        "\n",
        "print(np.argmax(a, axis=0))\n",
        "\n",
        "print(np.argmax(a, axis=1))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10 11 12]\n",
            " [13 14 15]]\n",
            "5\n",
            "[1 1 1]\n",
            "[2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}